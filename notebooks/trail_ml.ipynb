{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cdf0b4",
   "metadata": {},
   "source": [
    "# Import Library & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37034b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n",
      "Time: 2026-02-06 22:42:42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# ML\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('Libraries loaded')\n",
    "print(f'Time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409bb62",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ac2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 158 shoes × 57 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>terrain_light</th>\n",
       "      <th>terrain_moderate</th>\n",
       "      <th>terrain_technical</th>\n",
       "      <th>shock_low</th>\n",
       "      <th>shock_moderate</th>\n",
       "      <th>shock_high</th>\n",
       "      <th>energy_low</th>\n",
       "      <th>energy_moderate</th>\n",
       "      <th>...</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>season_all</th>\n",
       "      <th>heavy_runners</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>orthotic_friendly</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "      <th>lightweight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex agravic speed ultra</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex speed ultra</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild 2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>altra</td>\n",
       "      <td>lone peak 5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                        name  terrain_light  terrain_moderate  \\\n",
       "0  adidas  terrex agravic speed ultra              1                 0   \n",
       "1  adidas          terrex speed ultra              1                 0   \n",
       "2   altra             experience wild              1                 1   \n",
       "3   altra           experience wild 2              1                 0   \n",
       "4   altra               lone peak 5.0              1                 1   \n",
       "\n",
       "   terrain_technical  shock_low  shock_moderate  shock_high  energy_low  \\\n",
       "0                  0          0               1           0           0   \n",
       "1                  0          0               0           0           0   \n",
       "2                  0          0               1           0           1   \n",
       "3                  0          0               1           0           1   \n",
       "4                  0          0               0           0           0   \n",
       "\n",
       "   energy_moderate  ...  forefoot_lab_mm  season_summer  season_winter  \\\n",
       "0                0  ...             30.3              0              0   \n",
       "1                0  ...             24.6              0              0   \n",
       "2                0  ...             30.2              0              0   \n",
       "3                0  ...             26.2              0              0   \n",
       "4                0  ...             24.3              0              0   \n",
       "\n",
       "   season_all  heavy_runners  removable_insole  orthotic_friendly  waterproof  \\\n",
       "0           1              0                 1                  1           0   \n",
       "1           0              0                 1                  1           0   \n",
       "2           1              0                 1                  1           0   \n",
       "3           1              0                 1                  1           0   \n",
       "4           0              0                 1                  1           0   \n",
       "\n",
       "   water_repellent  lightweight  \n",
       "0                0            0  \n",
       "1                0            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                0            0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = '../data/trail_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Loaded: {df.shape[0]} shoes × {df.shape[1]} columns')\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"WARNING: '{file}' not found.\")\n",
    "    print(\"Please upload the correct dataset file to run with actual data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b87ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 57 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   brand                158 non-null    str    \n",
      " 1   name                 158 non-null    str    \n",
      " 2   terrain_light        158 non-null    int64  \n",
      " 3   terrain_moderate     158 non-null    int64  \n",
      " 4   terrain_technical    158 non-null    int64  \n",
      " 5   shock_low            158 non-null    int64  \n",
      " 6   shock_moderate       158 non-null    int64  \n",
      " 7   shock_high           158 non-null    int64  \n",
      " 8   energy_low           158 non-null    int64  \n",
      " 9   energy_moderate      158 non-null    int64  \n",
      " 10  energy_high          158 non-null    int64  \n",
      " 11  traction_moderate    158 non-null    int64  \n",
      " 12  traction_high        158 non-null    int64  \n",
      " 13  arch_neutral         158 non-null    int64  \n",
      " 14  arch_stability       158 non-null    int64  \n",
      " 15  weight_lab_oz        158 non-null    float64\n",
      " 16  drop_lab_mm          158 non-null    float64\n",
      " 17  strike_heel          158 non-null    int64  \n",
      " 18  strike_mid           158 non-null    int64  \n",
      " 19  strike_forefoot      158 non-null    int64  \n",
      " 20  softness_soft        158 non-null    int64  \n",
      " 21  softness_balanced    158 non-null    int64  \n",
      " 22  softness_firm        158 non-null    int64  \n",
      " 23  toebox_durability    158 non-null    int64  \n",
      " 24  heel_durability      158 non-null    int64  \n",
      " 25  outsole_durability   158 non-null    int64  \n",
      " 26  breathability        158 non-null    int64  \n",
      " 27  plate_0              158 non-null    int64  \n",
      " 28  plate_rock_plate     158 non-null    int64  \n",
      " 29  plate_carbon_plate   158 non-null    int64  \n",
      " 30  width_narrow         158 non-null    int64  \n",
      " 31  width_medium         158 non-null    int64  \n",
      " 32  width_wide           158 non-null    int64  \n",
      " 33  toebox_narrow        158 non-null    int64  \n",
      " 34  toebox_medium        158 non-null    int64  \n",
      " 35  toebox_wide          158 non-null    int64  \n",
      " 36  stiffness_flexible   158 non-null    int64  \n",
      " 37  stiffness_moderate   158 non-null    int64  \n",
      " 38  stiffness_stiff      158 non-null    int64  \n",
      " 39  torsional_flexible   158 non-null    int64  \n",
      " 40  torsional_moderate   158 non-null    int64  \n",
      " 41  torsional_stiff      158 non-null    int64  \n",
      " 42  heel_stiff_flexible  158 non-null    int64  \n",
      " 43  heel_stiff_moderate  158 non-null    int64  \n",
      " 44  heel_stiff_stiff     158 non-null    int64  \n",
      " 45  lug_depth            158 non-null    float64\n",
      " 46  heel_lab_mm          158 non-null    float64\n",
      " 47  forefoot_lab_mm      158 non-null    float64\n",
      " 48  season_summer        158 non-null    int64  \n",
      " 49  season_winter        158 non-null    int64  \n",
      " 50  season_all           158 non-null    int64  \n",
      " 51  heavy_runners        158 non-null    int64  \n",
      " 52  removable_insole     158 non-null    int64  \n",
      " 53  orthotic_friendly    158 non-null    int64  \n",
      " 54  waterproof           158 non-null    int64  \n",
      " 55  water_repellent      158 non-null    int64  \n",
      " 56  lightweight          158 non-null    int64  \n",
      "dtypes: float64(5), int64(50), str(2)\n",
      "memory usage: 70.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0f9b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44420bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 55 total\n",
      "  Binary     : 46\n",
      "  Continuous : 9\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "binary_cols = [col for col in numeric_cols if set(df[col].unique()).issubset({0, 1})]\n",
    "continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "\n",
    "print(f'Features: {len(numeric_cols)} total')\n",
    "print(f'  Binary     : {len(binary_cols)}')\n",
    "print(f'  Continuous : {len(continuous_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d852a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural input shape: (158, 55)\n",
      "Range: [0.000000, 1.000000]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = numeric_cols.copy()\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Separate for proper scaling\n",
    "X_binary = X[binary_cols].values\n",
    "X_continuous = X[continuous_cols].values\n",
    "\n",
    "# Scale continuous to 0-1 for neural network\n",
    "scaler_continuous = MinMaxScaler()\n",
    "X_continuous_scaled = scaler_continuous.fit_transform(X_continuous)\n",
    "\n",
    "# Combine\n",
    "X_combined = np.concatenate([X_binary, X_continuous_scaled], axis=1)\n",
    "\n",
    "# Also standard scaling for traditional comparison\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print(f'Neural input shape: {X_combined.shape}')\n",
    "print(f'Range: [{X_combined.min():.6f}, {X_combined.max():.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77513e",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b73e33",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2eb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,815</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │         \u001b[38;5;34m1,815\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,375</span> (21.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,375\u001b[0m (21.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,167</span> (20.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,167\u001b[0m (20.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> (832.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m208\u001b[0m (832.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Architecture\n",
    "input_dim = X_combined.shape[1]\n",
    "encoding_dims = [32, 16, 8]\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = input_layer\n",
    "for dim in encoding_dims:\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "latent = x\n",
    "\n",
    "# Decoder\n",
    "for dim in reversed(encoding_dims[:-1]):\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "encoder = Model(input_layer, latent)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print('Autoencoder architecture:')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaab33",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6fb0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Final loss: 0.102989\n",
      "  Val loss: 0.108489\n",
      "Latent space: (158, 8) (8D embeddings)\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_combined, X_combined,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f'Training done!')\n",
    "print(f'Final loss: {history.history[\"loss\"][-1]:.6f}')\n",
    "print(f'  Val loss: {history.history[\"val_loss\"][-1]:.6f}')\n",
    "\n",
    "# Get latent representations\n",
    "X_latent = encoder.predict(X_combined, verbose=0)\n",
    "print(f'Latent space: {X_latent.shape} (8D embeddings)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb6321",
   "metadata": {},
   "source": [
    "# Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601dd47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions ready\n"
     ]
    }
   ],
   "source": [
    "def calculate_cluster_purity(df, cluster_col, binary_cols):\n",
    "    \"\"\"\n",
    "    Calculates the purity of each cluster based on binary features.\n",
    "    Purity is defined as the mean dominance of the most frequent value (0 or 1)\n",
    "    within each binary column for a given cluster.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'by_cluster': A dictionary with purity and count for each cluster.\n",
    "            - 'mean_purity': The average purity across all clusters.\n",
    "            - 'min_purity': The minimum purity among all clusters.\n",
    "            - 'max_purity': The maximum purity among all clusters.\n",
    "    \"\"\"\n",
    "    purity_by_cluster = {}\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        dominances = []\n",
    "        for col in binary_cols:\n",
    "            if col in cdata.columns:\n",
    "                vc = cdata[col].value_counts()\n",
    "                if len(vc) > 0:\n",
    "                    dominances.append(vc.max() / n)\n",
    "        purity_by_cluster[cid] = {'purity': np.mean(dominances) if dominances else 0, 'n': n}\n",
    "    all_p = [v['purity'] for v in purity_by_cluster.values()]\n",
    "    return {\n",
    "        'by_cluster': purity_by_cluster,\n",
    "        'mean_purity': np.mean(all_p),\n",
    "        'min_purity': np.min(all_p),\n",
    "        'max_purity': np.max(all_p)\n",
    "    }\n",
    "\n",
    "def calculate_cluster_stability(X, labels, model_func, n_iter=20):\n",
    "    \"\"\"\n",
    "    Calculates the stability of clustering using the Adjusted Rand Index (ARI).\n",
    "    It performs bootstrapping by re-sampling the data and re-clustering to measure\n",
    "    how consistent the cluster assignments are.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The original cluster labels from the initial clustering.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (e.g., lambda: KMeans(n_clusters=k)).\n",
    "        n_iter (int, optional): The number of bootstrap iterations. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_ari': The mean Adjusted Rand Index.\n",
    "            - 'std_ari': The standard deviation of the ARI scores.\n",
    "            - 'stability_level': A categorical label (Excellent, Good, Moderate)\n",
    "                                 based on the mean ARI.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    ari_scores = []\n",
    "    for _ in range(n_iter):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        # Ensure model_func returns a new, untrained model each time\n",
    "        boot_model = model_func()\n",
    "        boot_labels = boot_model.fit_predict(X[idx])\n",
    "        ari = adjusted_rand_score(labels[idx], boot_labels)\n",
    "        ari_scores.append(ari)\n",
    "    m = np.mean(ari_scores)\n",
    "    return {\n",
    "        'mean_ari': m,\n",
    "        'std_ari': np.std(ari_scores),\n",
    "        'stability_level': 'Excellent' if m > 0.8 else 'Good' if m > 0.6 else 'Moderate'\n",
    "    }\n",
    "\n",
    "def calculate_interpretability_score(df, cluster_col, binary_cols, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Calculates an interpretability score for each cluster.\n",
    "    A cluster is considered more interpretable if a high proportion of its members\n",
    "    strongly exhibit (or strongly do not exhibit) certain binary features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "        threshold (float, optional): The threshold for defining strong exhibition.\n",
    "                                     A feature is 'strong' if its mean in a cluster\n",
    "                                     is > threshold or < (1 - threshold). Defaults to 0.75.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_interpretability': The average interpretability score across all clusters.\n",
    "            - 'scores': A list of interpretability scores for each cluster.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        strong = sum(1 for col in binary_cols if col in cdata.columns and\n",
    "                    (cdata[col].sum()/n > threshold or cdata[col].sum()/n < 1-threshold))\n",
    "        # Score is the proportion of binary features that are 'strong' for this cluster\n",
    "        scores.append(strong / len(binary_cols))\n",
    "    return {'mean_interpretability': np.mean(scores), 'scores': scores}\n",
    "\n",
    "def evaluate_clustering_comprehensive(X, labels, df_temp, model_func, binary_cols):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive evaluation of clustering results using multiple metrics.\n",
    "    It calculates Silhouette, Davies-Bouldin, Calinski-Harabasz scores, as well as\n",
    "    custom purity, stability, and interpretability scores.\n",
    "    A composite score is then calculated based on a weighted average of normalized metrics.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The cluster labels generated by the clustering algorithm.\n",
    "        df_temp (pd.DataFrame): A temporary DataFrame, copy of the original, to add cluster labels.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (used for stability calculation).\n",
    "        binary_cols (list): A list of column names in df_temp that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing various evaluation metrics and a composite score:\n",
    "            - 'silhouette': Silhouette Score.\n",
    "            - 'davies_bouldin': Davies-Bouldin Score.\n",
    "            - 'calinski_harabasz': Calinski-Harabasz Score.\n",
    "            - 'purity': Mean cluster purity.\n",
    "            - 'stability': Mean Adjusted Rand Index from stability testing.\n",
    "            - 'interpretability': Mean cluster interpretability score.\n",
    "            - 'composite_score': A weighted composite score of normalized metrics.\n",
    "    \"\"\"\n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    df_temp['cluster'] = labels\n",
    "    purity = calculate_cluster_purity(df_temp, 'cluster', binary_cols)\n",
    "    stability = calculate_cluster_stability(X, labels, model_func, 10)\n",
    "    interp = calculate_interpretability_score(df_temp, 'cluster', binary_cols)\n",
    "\n",
    "    # Normalize scores for composite calculation\n",
    "    sil_norm = (sil + 1) / 2\n",
    "    db_norm = 1 / (1 + db)\n",
    "    ch_norm = min(ch / 1000, 1)\n",
    "\n",
    "    # Composite score with example weights\n",
    "    composite = (0.25*sil_norm + 0.20*db_norm + 0.15*ch_norm +\n",
    "                 0.25*purity['mean_purity'] + 0.10*stability['mean_ari'] +\n",
    "                 0.05*interp['mean_interpretability'])\n",
    "\n",
    "    return {\n",
    "        'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch,\n",
    "        'purity': purity['mean_purity'], 'stability': stability['mean_ari'],\n",
    "        'interpretability': interp['mean_interpretability'], 'composite_score': composite\n",
    "    }\n",
    "\n",
    "print('Metrics functions ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ba812",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1f4985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  K  |  Score   |   Sil.   |    DB    |    CH     |  Purity  |  Stab.   |  Interp  |\n",
      "|-----+----------+----------+----------+-----------+----------+----------+----------|\n",
      "|  3  | 0.577096 | 0.314078 | 1.385059 | 64.689098 | 0.836800 | 0.767442 | 0.666667 |\n",
      "|  4  | 0.597972 | 0.338249 | 1.065373 | 71.222819 | 0.852908 | 0.724455 | 0.750000 |\n",
      "|  5  | 0.586065 | 0.294995 | 1.106011 | 73.497422 | 0.850139 | 0.693604 | 0.726087 |\n",
      "|  6  | 0.602437 | 0.320372 | 1.072173 | 73.707340 | 0.857554 | 0.781100 | 0.746377 |\n",
      "|  7  | 0.602879 | 0.321892 | 1.022535 | 69.834486 | 0.854789 | 0.773170 | 0.745342 |\n",
      "|  8  | 0.608751 | 0.321341 | 1.031879 | 68.203451 | 0.865018 | 0.795371 | 0.782609 |\n",
      "|  9  | 0.604693 | 0.320056 | 1.083768 | 66.142412 | 0.865268 | 0.786996 | 0.775362 |\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Header Tabel\n",
    "print(f\"| {'K':^3} | {'Score':^8} | {'Sil.':^8} | {'DB':^8} | {'CH':^9} | {'Purity':^8} | {'Stab.':^8} | {'Interp':^8} |\")\n",
    "print(f\"|{'-'*5}+{'-'*10}+{'-'*10}+{'-'*10}+{'-'*11}+{'-'*10}+{'-'*10}+{'-'*10}|\")\n",
    "\n",
    "for i in range(3, 10):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    model_factory = lambda: KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "    model = model_factory()\n",
    "    labels = model.fit_predict(X_latent)\n",
    "\n",
    "    metrics = evaluate_clustering_comprehensive(\n",
    "        X_latent, labels, df.copy(),\n",
    "        model_factory,\n",
    "        binary_cols\n",
    "    )\n",
    "\n",
    "    # Simpan hasil\n",
    "    results.append({\n",
    "        'k': i,\n",
    "        'model': model,\n",
    "        'labels': labels,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "    # Print Baris Tabel\n",
    "    print(f\"| {i:^3} | {metrics['composite_score']:<8.6f} | {metrics['silhouette']:<6.6f} | \"\n",
    "          f\"{metrics['davies_bouldin']:<6.6f} | {metrics['calinski_harabasz']:<8.6f} | \"\n",
    "          f\"{metrics['purity']:<6.6f} | {metrics['stability']:<6.6f} | {metrics['interpretability']:<6.6f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa23de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED BEST K: 8\n",
      "   Silhouette      : 0.321341\n",
      "   Composite Score : 0.608751\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "best_config = df_results.loc[df_results['composite_score'].idxmax()]\n",
    "\n",
    "best_model = best_config['model']\n",
    "best_labels = best_config['labels']\n",
    "best_k = best_config['k']\n",
    "X_for_clustering = X_latent\n",
    "\n",
    "print(f'SELECTED BEST K: {best_k}')\n",
    "print(f'   Silhouette      : {best_config[\"silhouette\"]:.6f}')\n",
    "print(f'   Composite Score : {best_config[\"composite_score\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedd13e",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb087b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('float64').columns.tolist():\n",
    "    new_col_name = col + '_bin'\n",
    "    df[new_col_name] = pd.qcut(df[col], q=3, labels=[0, 1, 2]).astype(int)\n",
    "\n",
    "# Reorder columns: non-numeric, binary, then continuous with their bins, then cluster\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "new_column_order = []\n",
    "\n",
    "# non-numeric columns\n",
    "for col in non_numeric_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# binary columns\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# continuous columns and their corresponding bin columns\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "    bin_col_name = col + '_bin'\n",
    "    if bin_col_name in df.columns:\n",
    "        new_column_order.append(bin_col_name)\n",
    "\n",
    "# Add the 'cluster' column\n",
    "if 'cluster' in df.columns and 'cluster' not in new_column_order:\n",
    "    new_column_order.append('cluster')\n",
    "\n",
    "# Reindex the DataFrame with the new order\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e638024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 62 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   brand                158 non-null    str    \n",
      " 1   name                 158 non-null    str    \n",
      " 2   terrain_light        158 non-null    int64  \n",
      " 3   terrain_moderate     158 non-null    int64  \n",
      " 4   terrain_technical    158 non-null    int64  \n",
      " 5   shock_low            158 non-null    int64  \n",
      " 6   shock_moderate       158 non-null    int64  \n",
      " 7   shock_high           158 non-null    int64  \n",
      " 8   energy_low           158 non-null    int64  \n",
      " 9   energy_moderate      158 non-null    int64  \n",
      " 10  energy_high          158 non-null    int64  \n",
      " 11  traction_moderate    158 non-null    int64  \n",
      " 12  traction_high        158 non-null    int64  \n",
      " 13  arch_neutral         158 non-null    int64  \n",
      " 14  arch_stability       158 non-null    int64  \n",
      " 15  strike_heel          158 non-null    int64  \n",
      " 16  strike_mid           158 non-null    int64  \n",
      " 17  strike_forefoot      158 non-null    int64  \n",
      " 18  softness_soft        158 non-null    int64  \n",
      " 19  softness_balanced    158 non-null    int64  \n",
      " 20  softness_firm        158 non-null    int64  \n",
      " 21  plate_0              158 non-null    int64  \n",
      " 22  plate_rock_plate     158 non-null    int64  \n",
      " 23  plate_carbon_plate   158 non-null    int64  \n",
      " 24  width_narrow         158 non-null    int64  \n",
      " 25  width_medium         158 non-null    int64  \n",
      " 26  width_wide           158 non-null    int64  \n",
      " 27  toebox_narrow        158 non-null    int64  \n",
      " 28  toebox_medium        158 non-null    int64  \n",
      " 29  toebox_wide          158 non-null    int64  \n",
      " 30  stiffness_flexible   158 non-null    int64  \n",
      " 31  stiffness_moderate   158 non-null    int64  \n",
      " 32  stiffness_stiff      158 non-null    int64  \n",
      " 33  torsional_flexible   158 non-null    int64  \n",
      " 34  torsional_moderate   158 non-null    int64  \n",
      " 35  torsional_stiff      158 non-null    int64  \n",
      " 36  heel_stiff_flexible  158 non-null    int64  \n",
      " 37  heel_stiff_moderate  158 non-null    int64  \n",
      " 38  heel_stiff_stiff     158 non-null    int64  \n",
      " 39  season_summer        158 non-null    int64  \n",
      " 40  season_winter        158 non-null    int64  \n",
      " 41  season_all           158 non-null    int64  \n",
      " 42  heavy_runners        158 non-null    int64  \n",
      " 43  removable_insole     158 non-null    int64  \n",
      " 44  orthotic_friendly    158 non-null    int64  \n",
      " 45  waterproof           158 non-null    int64  \n",
      " 46  water_repellent      158 non-null    int64  \n",
      " 47  lightweight          158 non-null    int64  \n",
      " 48  weight_lab_oz        158 non-null    float64\n",
      " 49  weight_lab_oz_bin    158 non-null    int64  \n",
      " 50  drop_lab_mm          158 non-null    float64\n",
      " 51  drop_lab_mm_bin      158 non-null    int64  \n",
      " 52  toebox_durability    158 non-null    int64  \n",
      " 53  heel_durability      158 non-null    int64  \n",
      " 54  outsole_durability   158 non-null    int64  \n",
      " 55  breathability        158 non-null    int64  \n",
      " 56  lug_depth            158 non-null    float64\n",
      " 57  lug_depth_bin        158 non-null    int64  \n",
      " 58  heel_lab_mm          158 non-null    float64\n",
      " 59  heel_lab_mm_bin      158 non-null    int64  \n",
      " 60  forefoot_lab_mm      158 non-null    float64\n",
      " 61  forefoot_lab_mm_bin  158 non-null    int64  \n",
      "dtypes: float64(5), int64(55), str(2)\n",
      "memory usage: 76.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84409589",
   "metadata": {},
   "source": [
    "# Generate Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58df965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>weight_lab_oz</th>\n",
       "      <th>drop_lab_mm</th>\n",
       "      <th>toebox_durability</th>\n",
       "      <th>heel_durability</th>\n",
       "      <th>outsole_durability</th>\n",
       "      <th>breathability</th>\n",
       "      <th>lug_depth</th>\n",
       "      <th>heel_lab_mm</th>\n",
       "      <th>...</th>\n",
       "      <th>stiffness</th>\n",
       "      <th>torsional</th>\n",
       "      <th>heel_stiff</th>\n",
       "      <th>season</th>\n",
       "      <th>heavy_runners</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>orthotic_friendly</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "      <th>lightweight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3.2%</td>\n",
       "      <td>10.32</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>30.98</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (100%)</td>\n",
       "      <td>flexible (40%)</td>\n",
       "      <td>flexible (20%)</td>\n",
       "      <td>summer (0%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>yes (80%)</td>\n",
       "      <td>yes (80%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>22.8%</td>\n",
       "      <td>9.82</td>\n",
       "      <td>4.68</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>29.82</td>\n",
       "      <td>...</td>\n",
       "      <td>moderate (81%)</td>\n",
       "      <td>stiff (47%)</td>\n",
       "      <td>flexible (64%)</td>\n",
       "      <td>all (86%)</td>\n",
       "      <td>no (6%)</td>\n",
       "      <td>yes (86%)</td>\n",
       "      <td>yes (86%)</td>\n",
       "      <td>no (11%)</td>\n",
       "      <td>no (3%)</td>\n",
       "      <td>no (17%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>13.3%</td>\n",
       "      <td>10.43</td>\n",
       "      <td>8.54</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.47</td>\n",
       "      <td>36.31</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (81%)</td>\n",
       "      <td>stiff (71%)</td>\n",
       "      <td>stiff (48%)</td>\n",
       "      <td>all (95%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (5%)</td>\n",
       "      <td>no (5%)</td>\n",
       "      <td>no (0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>17.1%</td>\n",
       "      <td>10.31</td>\n",
       "      <td>11.68</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.41</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.46</td>\n",
       "      <td>36.56</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (48%)</td>\n",
       "      <td>stiff (85%)</td>\n",
       "      <td>stiff (67%)</td>\n",
       "      <td>all (74%)</td>\n",
       "      <td>no (11%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (19%)</td>\n",
       "      <td>no (4%)</td>\n",
       "      <td>no (7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>10.35</td>\n",
       "      <td>7.78</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.54</td>\n",
       "      <td>33.51</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (68%)</td>\n",
       "      <td>stiff (80%)</td>\n",
       "      <td>moderate (92%)</td>\n",
       "      <td>all (96%)</td>\n",
       "      <td>no (8%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (4%)</td>\n",
       "      <td>no (8%)</td>\n",
       "      <td>no (0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>9.90</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.36</td>\n",
       "      <td>28.54</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (100%)</td>\n",
       "      <td>moderate (70%)</td>\n",
       "      <td>flexible (55%)</td>\n",
       "      <td>all (95%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>11.4%</td>\n",
       "      <td>10.63</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.45</td>\n",
       "      <td>34.61</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (100%)</td>\n",
       "      <td>stiff (89%)</td>\n",
       "      <td>stiff (78%)</td>\n",
       "      <td>all (50%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (11%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (6%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>9.93</td>\n",
       "      <td>5.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>28.28</td>\n",
       "      <td>...</td>\n",
       "      <td>stiff (100%)</td>\n",
       "      <td>stiff (17%)</td>\n",
       "      <td>flexible (33%)</td>\n",
       "      <td>summer (0%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (17%)</td>\n",
       "      <td>no (17%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (17%)</td>\n",
       "      <td>no (17%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count percentage  weight_lab_oz  drop_lab_mm  toebox_durability  \\\n",
       "0      5       3.2%          10.32         3.74               0.00   \n",
       "1     36      22.8%           9.82         4.68               3.28   \n",
       "2     21      13.3%          10.43         8.54               2.38   \n",
       "3     27      17.1%          10.31        11.68               3.22   \n",
       "4     25      15.8%          10.35         7.78               3.20   \n",
       "5     20      12.7%           9.90         4.10               1.70   \n",
       "6     18      11.4%          10.63        10.43               0.72   \n",
       "7      6       3.8%           9.93         5.53               0.00   \n",
       "\n",
       "   heel_durability  outsole_durability  breathability  lug_depth  heel_lab_mm  \\\n",
       "0             0.00                0.00           0.00       3.60        30.98   \n",
       "1             3.06                3.56           2.86       3.45        29.82   \n",
       "2             3.19                3.00           3.19       3.47        36.31   \n",
       "3             3.26                3.41           2.78       3.46        36.56   \n",
       "4             2.96                3.48           3.08       3.54        33.51   \n",
       "5             2.05                2.05           3.15       3.36        28.54   \n",
       "6             0.61                0.72           1.83       3.45        34.61   \n",
       "7             0.00                0.00           0.00       4.30        28.28   \n",
       "\n",
       "   ...       stiffness       torsional      heel_stiff       season  \\\n",
       "0  ...    stiff (100%)  flexible (40%)  flexible (20%)  summer (0%)   \n",
       "1  ...  moderate (81%)     stiff (47%)  flexible (64%)    all (86%)   \n",
       "2  ...     stiff (81%)     stiff (71%)     stiff (48%)    all (95%)   \n",
       "3  ...     stiff (48%)     stiff (85%)     stiff (67%)    all (74%)   \n",
       "4  ...     stiff (68%)     stiff (80%)  moderate (92%)    all (96%)   \n",
       "5  ...    stiff (100%)  moderate (70%)  flexible (55%)    all (95%)   \n",
       "6  ...    stiff (100%)     stiff (89%)     stiff (78%)    all (50%)   \n",
       "7  ...    stiff (100%)     stiff (17%)  flexible (33%)  summer (0%)   \n",
       "\n",
       "  heavy_runners removable_insole orthotic_friendly waterproof water_repellent  \\\n",
       "0       no (0%)        yes (80%)         yes (80%)    no (0%)         no (0%)   \n",
       "1       no (6%)        yes (86%)         yes (86%)   no (11%)         no (3%)   \n",
       "2       no (0%)       yes (100%)        yes (100%)    no (5%)         no (5%)   \n",
       "3      no (11%)       yes (100%)        yes (100%)   no (19%)         no (4%)   \n",
       "4       no (8%)       yes (100%)        yes (100%)    no (4%)         no (8%)   \n",
       "5       no (0%)       yes (100%)        yes (100%)    no (0%)         no (0%)   \n",
       "6       no (0%)       yes (100%)        yes (100%)   no (11%)         no (0%)   \n",
       "7       no (0%)         no (17%)          no (17%)    no (0%)        no (17%)   \n",
       "\n",
       "  lightweight  \n",
       "0     no (0%)  \n",
       "1    no (17%)  \n",
       "2     no (0%)  \n",
       "3     no (7%)  \n",
       "4     no (0%)  \n",
       "5     no (5%)  \n",
       "6     no (6%)  \n",
       "7    no (17%)  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Masukkan Cluster ke DataFrame\n",
    "df['cluster'] = best_labels \n",
    "\n",
    "# Setup Grouping\n",
    "bin_groups = {}\n",
    "for col in binary_cols:\n",
    "    parts = col.split('_')\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        prefix = '_'.join(parts[:-1])\n",
    "    else:\n",
    "        prefix = col\n",
    "        \n",
    "    bin_groups.setdefault(prefix, []).append(col)\n",
    "\n",
    "# Build Summary Data\n",
    "rows = []\n",
    "for cid in sorted(df['cluster'].unique()):\n",
    "    subset = df[df['cluster'] == cid]\n",
    "    n = len(subset)\n",
    "    \n",
    "    row = {'count': n, 'percentage': f\"{n/len(df)*100:.1f}%\"}\n",
    "\n",
    "    # A. Continuous Columns: Langsung ambil mean\n",
    "    for col in continuous_cols:\n",
    "        row[col.lower()] = round(subset[col].mean(), 2)\n",
    "\n",
    "    # B. Binary Groups\n",
    "    for prefix, cols in bin_groups.items():\n",
    "        # Hitung mean grup ini\n",
    "        means = subset[cols].mean()\n",
    "        best_col = means.idxmax()\n",
    "        best_val = means.max()\n",
    "        \n",
    "        # Case 1: Multiple Variants\n",
    "        if len(cols) > 1:\n",
    "            header = prefix.lower()\n",
    "            val_str = best_col.replace(f\"{prefix}_\", \"\").lower()\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "            \n",
    "        # Case 2: Standalone\n",
    "        else:\n",
    "            header = cols[0].lower()\n",
    "            val_str = \"yes\" if best_val > 0.5 else \"no\"\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame & Fix Display\n",
    "df_summary = pd.DataFrame(rows, index=sorted(df['cluster'].unique()))\n",
    "df_summary.index.name = None \n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "display(df_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
