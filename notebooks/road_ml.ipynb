{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cdf0b4",
   "metadata": {},
   "source": [
    "# Import Library & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d37034b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n",
      "Time: 2026-02-07 09:34:23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# ML\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('Libraries loaded')\n",
    "print(f'Time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97aa73",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea0a9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 434 shoes × 45 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>lightweight</th>\n",
       "      <th>rocker</th>\n",
       "      <th>orthotic_friendly</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>pace_daily_running</th>\n",
       "      <th>pace_tempo</th>\n",
       "      <th>pace_competition</th>\n",
       "      <th>arch_neutral</th>\n",
       "      <th>...</th>\n",
       "      <th>heel_stiff_flexible</th>\n",
       "      <th>heel_stiff_moderate</th>\n",
       "      <th>heel_stiff_stiff</th>\n",
       "      <th>plate_rock</th>\n",
       "      <th>plate_carbon</th>\n",
       "      <th>heel_lab_mm</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>season_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brooks</td>\n",
       "      <td>launch 9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brooks</td>\n",
       "      <td>levitate 6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>26.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adidas</td>\n",
       "      <td>4dfwd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adidas</td>\n",
       "      <td>4dfwd 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adidas</td>\n",
       "      <td>4dfwd 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand        name  lightweight  rocker  orthotic_friendly  \\\n",
       "0  brooks    launch 9            1       0                  1   \n",
       "1  brooks  levitate 6            0       0                  1   \n",
       "2  adidas       4dfwd            0       0                  1   \n",
       "3  adidas     4dfwd 2            0       0                  1   \n",
       "4  adidas     4dfwd 3            0       0                  1   \n",
       "\n",
       "   removable_insole  pace_daily_running  pace_tempo  pace_competition  \\\n",
       "0                 1                   1           1                 0   \n",
       "1                 1                   1           0                 0   \n",
       "2                 1                   1           0                 0   \n",
       "3                 1                   1           0                 0   \n",
       "4                 1                   1           0                 0   \n",
       "\n",
       "   arch_neutral  ...  heel_stiff_flexible  heel_stiff_moderate  \\\n",
       "0             1  ...                    1                    0   \n",
       "1             1  ...                    0                    1   \n",
       "2             1  ...                    1                    0   \n",
       "3             1  ...                    0                    1   \n",
       "4             1  ...                    1                    0   \n",
       "\n",
       "   heel_stiff_stiff  plate_rock  plate_carbon  heel_lab_mm  forefoot_lab_mm  \\\n",
       "0                 0           0             0         32.4             23.0   \n",
       "1                 0           0             0         34.3             26.6   \n",
       "2                 0           0             0         33.3             24.4   \n",
       "3                 0           0             0         31.8             21.2   \n",
       "4                 0           0             0         32.6             22.7   \n",
       "\n",
       "   season_summer  season_winter  season_all  \n",
       "0              0              0           0  \n",
       "1              1              0           1  \n",
       "2              0              0           1  \n",
       "3              0              0           1  \n",
       "4              0              0           1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = '../data/road_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Loaded: {df.shape[0]} shoes × {df.shape[1]} columns')\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"WARNING: '{file}' not found.\")\n",
    "    print(\"Please upload the correct dataset file to run with actual data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff806013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 434 entries, 0 to 433\n",
      "Data columns (total 45 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   brand                434 non-null    str    \n",
      " 1   name                 434 non-null    str    \n",
      " 2   lightweight          434 non-null    int64  \n",
      " 3   rocker               434 non-null    int64  \n",
      " 4   orthotic_friendly    434 non-null    int64  \n",
      " 5   removable_insole     434 non-null    int64  \n",
      " 6   pace_daily_running   434 non-null    int64  \n",
      " 7   pace_tempo           434 non-null    int64  \n",
      " 8   pace_competition     434 non-null    int64  \n",
      " 9   arch_neutral         434 non-null    int64  \n",
      " 10  arch_stability       434 non-null    int64  \n",
      " 11  weight_lab_oz        434 non-null    float64\n",
      " 12  drop_lab_mm          434 non-null    float64\n",
      " 13  strike_heel          434 non-null    int64  \n",
      " 14  strike_mid           434 non-null    int64  \n",
      " 15  strike_forefoot      434 non-null    int64  \n",
      " 16  softness_soft        434 non-null    int64  \n",
      " 17  softness_balanced    434 non-null    int64  \n",
      " 18  softness_firm        434 non-null    int64  \n",
      " 19  toebox_durability    434 non-null    int64  \n",
      " 20  heel_durability      434 non-null    int64  \n",
      " 21  outsole_durability   434 non-null    int64  \n",
      " 22  breathability        434 non-null    int64  \n",
      " 23  width_narrow         434 non-null    int64  \n",
      " 24  width_medium         434 non-null    int64  \n",
      " 25  width_wide           434 non-null    int64  \n",
      " 26  toebox_narrow        434 non-null    int64  \n",
      " 27  toebox_medium        434 non-null    int64  \n",
      " 28  toebox_wide          434 non-null    int64  \n",
      " 29  stiffness_flexible   434 non-null    int64  \n",
      " 30  stiffness_moderate   434 non-null    int64  \n",
      " 31  stiffness_stiff      434 non-null    int64  \n",
      " 32  torsional_flexible   434 non-null    int64  \n",
      " 33  torsional_moderate   434 non-null    int64  \n",
      " 34  torsional_stiff      434 non-null    int64  \n",
      " 35  heel_stiff_flexible  434 non-null    int64  \n",
      " 36  heel_stiff_moderate  434 non-null    int64  \n",
      " 37  heel_stiff_stiff     434 non-null    int64  \n",
      " 38  plate_rock           434 non-null    int64  \n",
      " 39  plate_carbon         434 non-null    int64  \n",
      " 40  heel_lab_mm          434 non-null    float64\n",
      " 41  forefoot_lab_mm      434 non-null    float64\n",
      " 42  season_summer        434 non-null    int64  \n",
      " 43  season_winter        434 non-null    int64  \n",
      " 44  season_all           434 non-null    int64  \n",
      "dtypes: float64(4), int64(39), str(2)\n",
      "memory usage: 152.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2caea",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f7f5da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 43 total\n",
      "  Binary     : 35\n",
      "  Continuous : 8\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "binary_cols = [col for col in numeric_cols if set(df[col].unique()).issubset({0, 1})]\n",
    "continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "\n",
    "print(f'Features: {len(numeric_cols)} total')\n",
    "print(f'  Binary     : {len(binary_cols)}')\n",
    "print(f'  Continuous : {len(continuous_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04a0228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural input shape: (434, 43)\n",
      "Range: [0.000000, 1.000000]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = numeric_cols.copy()\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Separate for proper scaling\n",
    "X_binary = X[binary_cols].values\n",
    "X_continuous = X[continuous_cols].values\n",
    "\n",
    "# Scale continuous to 0-1 for neural network\n",
    "scaler_continuous = MinMaxScaler()\n",
    "X_continuous_scaled = scaler_continuous.fit_transform(X_continuous)\n",
    "\n",
    "# Combine\n",
    "X_combined = np.concatenate([X_binary, X_continuous_scaled], axis=1)\n",
    "\n",
    "# Also standard scaling for traditional comparison\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print(f'Neural input shape: {X_combined.shape}')\n",
    "print(f'Range: [{X_combined.min():.6f}, {X_combined.max():.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05980d55",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be84505",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e286cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,595</span> (17.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,595\u001b[0m (17.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,387</span> (17.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,387\u001b[0m (17.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> (832.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m208\u001b[0m (832.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Architecture\n",
    "input_dim = X_combined.shape[1]\n",
    "encoding_dims = [32, 16, 8]\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = input_layer\n",
    "for dim in encoding_dims:\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "latent = x\n",
    "\n",
    "# Decoder\n",
    "for dim in reversed(encoding_dims[:-1]):\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "encoder = Model(input_layer, latent)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print('Autoencoder architecture:')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb013f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f610379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Final loss: 0.098594\n",
      "  Val loss: 0.080011\n",
      "Latent space: (434, 8) (8D embeddings)\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_combined, X_combined,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f'Training done!')\n",
    "print(f'Final loss: {history.history[\"loss\"][-1]:.6f}')\n",
    "print(f'  Val loss: {history.history[\"val_loss\"][-1]:.6f}')\n",
    "\n",
    "# Get latent representations\n",
    "X_latent = encoder.predict(X_combined, verbose=0)\n",
    "print(f'Latent space: {X_latent.shape} (8D embeddings)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d811ee5",
   "metadata": {},
   "source": [
    "# Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6f5f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions ready\n"
     ]
    }
   ],
   "source": [
    "def calculate_cluster_purity(df, cluster_col, binary_cols):\n",
    "    \"\"\"\n",
    "    Calculates the purity of each cluster based on binary features.\n",
    "    Purity is defined as the mean dominance of the most frequent value (0 or 1)\n",
    "    within each binary column for a given cluster.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'by_cluster': A dictionary with purity and count for each cluster.\n",
    "            - 'mean_purity': The average purity across all clusters.\n",
    "            - 'min_purity': The minimum purity among all clusters.\n",
    "            - 'max_purity': The maximum purity among all clusters.\n",
    "    \"\"\"\n",
    "    purity_by_cluster = {}\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        dominances = []\n",
    "        for col in binary_cols:\n",
    "            if col in cdata.columns:\n",
    "                vc = cdata[col].value_counts()\n",
    "                if len(vc) > 0:\n",
    "                    dominances.append(vc.max() / n)\n",
    "        purity_by_cluster[cid] = {'purity': np.mean(dominances) if dominances else 0, 'n': n}\n",
    "    all_p = [v['purity'] for v in purity_by_cluster.values()]\n",
    "    return {\n",
    "        'by_cluster': purity_by_cluster,\n",
    "        'mean_purity': np.mean(all_p),\n",
    "        'min_purity': np.min(all_p),\n",
    "        'max_purity': np.max(all_p)\n",
    "    }\n",
    "\n",
    "def calculate_cluster_stability(X, labels, model_func, n_iter=20):\n",
    "    \"\"\"\n",
    "    Calculates the stability of clustering using the Adjusted Rand Index (ARI).\n",
    "    It performs bootstrapping by re-sampling the data and re-clustering to measure\n",
    "    how consistent the cluster assignments are.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The original cluster labels from the initial clustering.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (e.g., `lambda: KMeans(n_clusters=k)`).\n",
    "        n_iter (int, optional): The number of bootstrap iterations. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_ari': The mean Adjusted Rand Index.\n",
    "            - 'std_ari': The standard deviation of the ARI scores.\n",
    "            - 'stability_level': A categorical label (Excellent, Good, Moderate)\n",
    "                                 based on the mean ARI.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    ari_scores = []\n",
    "    for _ in range(n_iter):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        # Ensure model_func returns a new, untrained model each time\n",
    "        boot_model = model_func()\n",
    "        boot_labels = boot_model.fit_predict(X[idx])\n",
    "        ari = adjusted_rand_score(labels[idx], boot_labels)\n",
    "        ari_scores.append(ari)\n",
    "    m = np.mean(ari_scores)\n",
    "    return {\n",
    "        'mean_ari': m,\n",
    "        'std_ari': np.std(ari_scores),\n",
    "        'stability_level': 'Excellent' if m > 0.8 else 'Good' if m > 0.6 else 'Moderate'\n",
    "    }\n",
    "\n",
    "def calculate_interpretability_score(df, cluster_col, binary_cols, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Calculates an interpretability score for each cluster.\n",
    "    A cluster is considered more interpretable if a high proportion of its members\n",
    "    strongly exhibit (or strongly do not exhibit) certain binary features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "        threshold (float, optional): The threshold for defining strong exhibition.\n",
    "                                     A feature is 'strong' if its mean in a cluster\n",
    "                                     is > threshold or < (1 - threshold). Defaults to 0.75.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_interpretability': The average interpretability score across all clusters.\n",
    "            - 'scores': A list of interpretability scores for each cluster.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        strong = sum(1 for col in binary_cols if col in cdata.columns and\n",
    "                    (cdata[col].sum()/n > threshold or cdata[col].sum()/n < 1-threshold))\n",
    "        # Score is the proportion of binary features that are 'strong' for this cluster\n",
    "        scores.append(strong / len(binary_cols))\n",
    "    return {'mean_interpretability': np.mean(scores), 'scores': scores}\n",
    "\n",
    "def evaluate_clustering_comprehensive(X, labels, df_temp, model_func, binary_cols):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive evaluation of clustering results using multiple metrics.\n",
    "    It calculates Silhouette, Davies-Bouldin, Calinski-Harabasz scores, as well as\n",
    "    custom purity, stability, and interpretability scores.\n",
    "    A composite score is then calculated based on a weighted average of normalized metrics.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The cluster labels generated by the clustering algorithm.\n",
    "        df_temp (pd.DataFrame): A temporary DataFrame, copy of the original, to add cluster labels.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (used for stability calculation).\n",
    "        binary_cols (list): A list of column names in df_temp that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing various evaluation metrics and a composite score:\n",
    "            - 'silhouette': Silhouette Score.\n",
    "            - 'davies_bouldin': Davies-Bouldin Score.\n",
    "            - 'calinski_harabasz': Calinski-Harabasz Score.\n",
    "            - 'purity': Mean cluster purity.\n",
    "            - 'stability': Mean Adjusted Rand Index from stability testing.\n",
    "            - 'interpretability': Mean cluster interpretability score.\n",
    "            - 'composite_score': A weighted composite score of normalized metrics.\n",
    "    \"\"\"\n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    df_temp['cluster'] = labels\n",
    "    purity = calculate_cluster_purity(df_temp, 'cluster', binary_cols)\n",
    "    stability = calculate_cluster_stability(X, labels, model_func, 10)\n",
    "    interp = calculate_interpretability_score(df_temp, 'cluster', binary_cols)\n",
    "\n",
    "    # Normalize scores for composite calculation\n",
    "    sil_norm = (sil + 1) / 2\n",
    "    db_norm = 1 / (1 + db)\n",
    "    ch_norm = min(ch / 1000, 1)\n",
    "\n",
    "    # Composite score with example weights\n",
    "    composite = (0.25*sil_norm + 0.20*db_norm + 0.15*ch_norm +\n",
    "                 0.25*purity['mean_purity'] + 0.10*stability['mean_ari'] +\n",
    "                 0.05*interp['mean_interpretability'])\n",
    "\n",
    "    return {\n",
    "        'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch,\n",
    "        'purity': purity['mean_purity'], 'stability': stability['mean_ari'],\n",
    "        'interpretability': interp['mean_interpretability'], 'composite_score': composite\n",
    "    }\n",
    "\n",
    "print('Metrics functions ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8373ffc",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d78a6cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  K  |  Score   |   Sil.   |    DB    |     CH     |  Purity  |  Stab.   |  Interp  |\n",
      "|-----+----------+----------+----------+------------+----------+----------+----------|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  3  | 0.611811 | 0.319946 | 1.242266 | 171.224326 | 0.813811 | 0.946766 | 0.676190 |\n",
      "|  4  | 0.617747 | 0.324881 | 1.108687 | 171.307581 | 0.818873 | 0.940191 | 0.657143 |\n",
      "|  5  | 0.583616 | 0.274600 | 1.197150 | 160.760427 | 0.823986 | 0.694395 | 0.674286 |\n",
      "|  6  | 0.570967 | 0.267507 | 1.276576 | 153.654779 | 0.828917 | 0.605901 | 0.676190 |\n",
      "|  7  | 0.592353 | 0.290334 | 1.080646 | 155.590626 | 0.844532 | 0.651598 | 0.706122 |\n",
      "|  8  | 0.598447 | 0.293481 | 1.100966 | 155.294507 | 0.847696 | 0.693848 | 0.739286 |\n",
      "|  9  | 0.589185 | 0.286266 | 1.089457 | 151.626006 | 0.849579 | 0.611948 | 0.726984 |\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Header Tabel\n",
    "print(f\"| {'K':^3} | {'Score':^8} | {'Sil.':^8} | {'DB':^8} | {'CH':^10} | {'Purity':^8} | {'Stab.':^8} | {'Interp':^8} |\")\n",
    "print(f\"|{'-'*5}+{'-'*10}+{'-'*10}+{'-'*10}+{'-'*12}+{'-'*10}+{'-'*10}+{'-'*10}|\")\n",
    "\n",
    "for i in range(3, 10):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    model_factory = lambda: KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "    model = model_factory()\n",
    "    labels = model.fit_predict(X_latent)\n",
    "\n",
    "    metrics = evaluate_clustering_comprehensive(\n",
    "        X_latent, labels, df.copy(),\n",
    "        model_factory,\n",
    "        binary_cols\n",
    "    )\n",
    "\n",
    "    # Simpan hasil\n",
    "    results.append({\n",
    "        'k': i,\n",
    "        'model': model,\n",
    "        'labels': labels,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "    # Print Baris Tabel\n",
    "    print(f\"| {i:^3} | {metrics['composite_score']:<8.6f} | {metrics['silhouette']:<6.6f} | \"\n",
    "          f\"{metrics['davies_bouldin']:<6.6f} | {metrics['calinski_harabasz']:<8.6f} | \"\n",
    "          f\"{metrics['purity']:<6.6f} | {metrics['stability']:<6.6f} | {metrics['interpretability']:<6.6f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bad2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED BEST K: 4\n",
      "   Silhouette      : 0.324881\n",
      "   Composite Score : 0.617747\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "best_config = df_results.loc[df_results['composite_score'].idxmax()]\n",
    "\n",
    "best_model = best_config['model']\n",
    "best_labels = best_config['labels']\n",
    "best_k = best_config['k']\n",
    "X_for_clustering = X_latent\n",
    "\n",
    "print(f'SELECTED BEST K: {best_k}')\n",
    "print(f'   Silhouette      : {best_config[\"silhouette\"]:.6f}')\n",
    "print(f'   Composite Score : {best_config[\"composite_score\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384d05b",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f5aaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('float64').columns.tolist():\n",
    "    new_col_name = col + '_bin'\n",
    "    df[new_col_name] = pd.qcut(df[col], q=3, labels=[0, 1, 2]).astype(int)\n",
    "\n",
    "# Reorder columns: non-numeric, binary, then continuous with their bins, then cluster\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "new_column_order = []\n",
    "\n",
    "# non-numeric columns\n",
    "for col in non_numeric_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# binary columns\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# continuous columns and their corresponding bin columns\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "    bin_col_name = col + '_bin'\n",
    "    if bin_col_name in df.columns:\n",
    "        new_column_order.append(bin_col_name)\n",
    "\n",
    "# Add the 'cluster' column\n",
    "if 'cluster' in df.columns and 'cluster' not in new_column_order:\n",
    "    new_column_order.append('cluster')\n",
    "\n",
    "# Reindex the DataFrame with the new order\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3309c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 434 entries, 0 to 433\n",
      "Data columns (total 49 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   brand                434 non-null    str    \n",
      " 1   name                 434 non-null    str    \n",
      " 2   lightweight          434 non-null    int64  \n",
      " 3   rocker               434 non-null    int64  \n",
      " 4   orthotic_friendly    434 non-null    int64  \n",
      " 5   removable_insole     434 non-null    int64  \n",
      " 6   pace_daily_running   434 non-null    int64  \n",
      " 7   pace_tempo           434 non-null    int64  \n",
      " 8   pace_competition     434 non-null    int64  \n",
      " 9   arch_neutral         434 non-null    int64  \n",
      " 10  arch_stability       434 non-null    int64  \n",
      " 11  strike_heel          434 non-null    int64  \n",
      " 12  strike_mid           434 non-null    int64  \n",
      " 13  strike_forefoot      434 non-null    int64  \n",
      " 14  softness_soft        434 non-null    int64  \n",
      " 15  softness_balanced    434 non-null    int64  \n",
      " 16  softness_firm        434 non-null    int64  \n",
      " 17  width_narrow         434 non-null    int64  \n",
      " 18  width_medium         434 non-null    int64  \n",
      " 19  width_wide           434 non-null    int64  \n",
      " 20  toebox_narrow        434 non-null    int64  \n",
      " 21  toebox_medium        434 non-null    int64  \n",
      " 22  toebox_wide          434 non-null    int64  \n",
      " 23  stiffness_flexible   434 non-null    int64  \n",
      " 24  stiffness_moderate   434 non-null    int64  \n",
      " 25  stiffness_stiff      434 non-null    int64  \n",
      " 26  torsional_flexible   434 non-null    int64  \n",
      " 27  torsional_moderate   434 non-null    int64  \n",
      " 28  torsional_stiff      434 non-null    int64  \n",
      " 29  heel_stiff_flexible  434 non-null    int64  \n",
      " 30  heel_stiff_moderate  434 non-null    int64  \n",
      " 31  heel_stiff_stiff     434 non-null    int64  \n",
      " 32  plate_rock           434 non-null    int64  \n",
      " 33  plate_carbon         434 non-null    int64  \n",
      " 34  season_summer        434 non-null    int64  \n",
      " 35  season_winter        434 non-null    int64  \n",
      " 36  season_all           434 non-null    int64  \n",
      " 37  weight_lab_oz        434 non-null    float64\n",
      " 38  weight_lab_oz_bin    434 non-null    int64  \n",
      " 39  drop_lab_mm          434 non-null    float64\n",
      " 40  drop_lab_mm_bin      434 non-null    int64  \n",
      " 41  toebox_durability    434 non-null    int64  \n",
      " 42  heel_durability      434 non-null    int64  \n",
      " 43  outsole_durability   434 non-null    int64  \n",
      " 44  breathability        434 non-null    int64  \n",
      " 45  heel_lab_mm          434 non-null    float64\n",
      " 46  heel_lab_mm_bin      434 non-null    int64  \n",
      " 47  forefoot_lab_mm      434 non-null    float64\n",
      " 48  forefoot_lab_mm_bin  434 non-null    int64  \n",
      "dtypes: float64(4), int64(43), str(2)\n",
      "memory usage: 166.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318097d",
   "metadata": {},
   "source": [
    "# Generate Cluster Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03ab527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>weight_lab_oz</th>\n",
       "      <th>drop_lab_mm</th>\n",
       "      <th>toebox_durability</th>\n",
       "      <th>heel_durability</th>\n",
       "      <th>outsole_durability</th>\n",
       "      <th>breathability</th>\n",
       "      <th>heel_lab_mm</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>...</th>\n",
       "      <th>arch</th>\n",
       "      <th>strike</th>\n",
       "      <th>softness</th>\n",
       "      <th>width</th>\n",
       "      <th>toebox</th>\n",
       "      <th>stiffness</th>\n",
       "      <th>torsional</th>\n",
       "      <th>heel_stiff</th>\n",
       "      <th>plate</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>11.1%</td>\n",
       "      <td>7.66</td>\n",
       "      <td>8.57</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.44</td>\n",
       "      <td>4.08</td>\n",
       "      <td>38.02</td>\n",
       "      <td>29.45</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (77%)</td>\n",
       "      <td>soft (65%)</td>\n",
       "      <td>narrow (65%)</td>\n",
       "      <td>medium (48%)</td>\n",
       "      <td>stiff (94%)</td>\n",
       "      <td>stiff (100%)</td>\n",
       "      <td>flexible (90%)</td>\n",
       "      <td>carbon (96%)</td>\n",
       "      <td>all (94%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230</td>\n",
       "      <td>53.0%</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.02</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.27</td>\n",
       "      <td>36.20</td>\n",
       "      <td>27.19</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral (80%)</td>\n",
       "      <td>heel (74%)</td>\n",
       "      <td>balanced (53%)</td>\n",
       "      <td>medium (74%)</td>\n",
       "      <td>medium (70%)</td>\n",
       "      <td>moderate (53%)</td>\n",
       "      <td>stiff (63%)</td>\n",
       "      <td>stiff (43%)</td>\n",
       "      <td>carbon (4%)</td>\n",
       "      <td>all (96%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>21.7%</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.43</td>\n",
       "      <td>33.14</td>\n",
       "      <td>24.01</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral (84%)</td>\n",
       "      <td>heel (69%)</td>\n",
       "      <td>balanced (27%)</td>\n",
       "      <td>narrow (50%)</td>\n",
       "      <td>narrow (6%)</td>\n",
       "      <td>stiff (81%)</td>\n",
       "      <td>moderate (44%)</td>\n",
       "      <td>moderate (26%)</td>\n",
       "      <td>carbon (2%)</td>\n",
       "      <td>all (44%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>14.3%</td>\n",
       "      <td>7.83</td>\n",
       "      <td>6.17</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.48</td>\n",
       "      <td>28.84</td>\n",
       "      <td>22.70</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral (97%)</td>\n",
       "      <td>mid (97%)</td>\n",
       "      <td>soft (52%)</td>\n",
       "      <td>medium (45%)</td>\n",
       "      <td>medium (34%)</td>\n",
       "      <td>moderate (58%)</td>\n",
       "      <td>flexible (65%)</td>\n",
       "      <td>flexible (63%)</td>\n",
       "      <td>carbon (5%)</td>\n",
       "      <td>all (92%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count percentage  weight_lab_oz  drop_lab_mm  toebox_durability  \\\n",
       "0     48      11.1%           7.66         8.57               2.06   \n",
       "1    230      53.0%           9.95         9.02               3.02   \n",
       "2     94      21.7%           9.80         9.12               0.12   \n",
       "3     62      14.3%           7.83         6.17               2.10   \n",
       "\n",
       "   heel_durability  outsole_durability  breathability  heel_lab_mm  \\\n",
       "0             2.77                2.44           4.08        38.02   \n",
       "1             3.38                3.57           3.27        36.20   \n",
       "2             0.13                0.04           1.43        33.14   \n",
       "3             2.31                2.34           3.48        28.84   \n",
       "\n",
       "   forefoot_lab_mm  ...            arch      strike        softness  \\\n",
       "0            29.45  ...  neutral (100%)   mid (77%)      soft (65%)   \n",
       "1            27.19  ...   neutral (80%)  heel (74%)  balanced (53%)   \n",
       "2            24.01  ...   neutral (84%)  heel (69%)  balanced (27%)   \n",
       "3            22.70  ...   neutral (97%)   mid (97%)      soft (52%)   \n",
       "\n",
       "          width        toebox       stiffness       torsional      heel_stiff  \\\n",
       "0  narrow (65%)  medium (48%)     stiff (94%)    stiff (100%)  flexible (90%)   \n",
       "1  medium (74%)  medium (70%)  moderate (53%)     stiff (63%)     stiff (43%)   \n",
       "2  narrow (50%)   narrow (6%)     stiff (81%)  moderate (44%)  moderate (26%)   \n",
       "3  medium (45%)  medium (34%)  moderate (58%)  flexible (65%)  flexible (63%)   \n",
       "\n",
       "          plate     season  \n",
       "0  carbon (96%)  all (94%)  \n",
       "1   carbon (4%)  all (96%)  \n",
       "2   carbon (2%)  all (44%)  \n",
       "3   carbon (5%)  all (92%)  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Masukkan Cluster ke DataFrame\n",
    "df['cluster'] = best_labels \n",
    "\n",
    "# Setup Grouping\n",
    "bin_groups = {}\n",
    "for col in binary_cols:\n",
    "    parts = col.split('_')\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        prefix = '_'.join(parts[:-1])\n",
    "    else:\n",
    "        prefix = col\n",
    "        \n",
    "    bin_groups.setdefault(prefix, []).append(col)\n",
    "\n",
    "# Build Summary Data\n",
    "rows = []\n",
    "for cid in sorted(df['cluster'].unique()):\n",
    "    subset = df[df['cluster'] == cid]\n",
    "    n = len(subset)\n",
    "    \n",
    "    row = {'count': n, 'percentage': f\"{n/len(df)*100:.1f}%\"}\n",
    "\n",
    "    # A. Continuous Columns: Langsung ambil mean\n",
    "    for col in continuous_cols:\n",
    "        row[col.lower()] = round(subset[col].mean(), 2)\n",
    "\n",
    "    # B. Binary Groups\n",
    "    for prefix, cols in bin_groups.items():\n",
    "        # Hitung mean grup ini\n",
    "        means = subset[cols].mean()\n",
    "        best_col = means.idxmax()\n",
    "        best_val = means.max()\n",
    "        \n",
    "        # Case 1: Multiple Variants\n",
    "        if len(cols) > 1:\n",
    "            header = prefix.lower()\n",
    "            val_str = best_col.replace(f\"{prefix}_\", \"\").lower()\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "            \n",
    "        # Case 2: Standalone\n",
    "        else:\n",
    "            header = cols[0].lower()\n",
    "            val_str = \"yes\" if best_val > 0.5 else \"no\"\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame & Fix Display\n",
    "df_summary = pd.DataFrame(rows, index=sorted(df['cluster'].unique()))\n",
    "df_summary.index.name = None \n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21add3",
   "metadata": {},
   "source": [
    "# Deep Learn Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83f48aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "# --- HELPER: Priority Logic ---\n",
    "def get_priority_val(user_input, priority_list, mapping_dicts):\n",
    "    \"\"\"\n",
    "    Mengambil nilai dari source dengan prioritas tertinggi yang diisi user.\n",
    "    Jika input prioritas tinggi ada, abaikan input prioritas rendah.\n",
    "    \"\"\"\n",
    "    for source_key in priority_list:\n",
    "        if source_key in user_input and user_input[source_key]:\n",
    "            user_choice = user_input[source_key]\n",
    "            if source_key in mapping_dicts:\n",
    "                mapping = mapping_dicts[source_key]\n",
    "                if user_choice in mapping:\n",
    "                    return mapping[user_choice]\n",
    "    return 0.5  # Default Neutral\n",
    "\n",
    "# --- PREPROCESSING & MASKING ---\n",
    "def preprocess_user_input_with_mask(user_input, binary_cols, continuous_cols):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    1. full_vector_raw: Vector lengkap (isi 0.5 jika kosong) -> Untuk masuk ke Autoencoder.\n",
    "    2. valid_indices: Index kolom yang BENAR-BENAR diisi user -> Untuk perhitungan Similarity score.\n",
    "    \"\"\"\n",
    "    feats = {col: 0.0 for col in binary_cols + continuous_cols}\n",
    "    \n",
    "    # MAPPINGS (Normalized 0, 0.5, 1)\n",
    "    map_pace_light = {'Easy': 0.5, 'Steady': 0.5, 'Fast': 1.0}\n",
    "    map_pace_drop  = {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0} # Easy=High Drop\n",
    "\n",
    "    # 1. SIMPLE FEATURES (1 Source)\n",
    "    feats['lightweight'] = get_priority_val(user_input, ['pace'], {'pace': map_pace_light})\n",
    "    feats['rocker'] = get_priority_val(user_input, ['running_purpose'], {'running_purpose': {'Race': 1.0, 'Tempo': 0.5, 'Daily': 0.0}})\n",
    "    \n",
    "    orth_val = get_priority_val(user_input, ['orthotic_usage'], {'orthotic_usage': {'Yes': 1.0, 'No': 0.5}})\n",
    "    feats['orthotic_friendly'] = orth_val\n",
    "    feats['removable_insole'] = orth_val\n",
    "    \n",
    "    purp = user_input.get('running_purpose', 'Daily')\n",
    "    feats['pace_daily_running'] = 1.0 if purp == 'Daily' else (0.5 if purp == 'Tempo' else 0.0)\n",
    "    feats['pace_tempo']         = 1.0 if purp == 'Tempo' else 0.5\n",
    "    feats['pace_competition']   = 1.0 if purp == 'Race' else (0.5 if purp == 'Tempo' else 0.0)\n",
    "\n",
    "    feats['arch_neutral']   = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 0.0, 'Neutral': 0.8, 'High': 1.0}})\n",
    "    feats['arch_stability'] = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 1.0, 'Neutral': 0.2, 'High': 0.0}})\n",
    "    \n",
    "    feats['drop_lab_mm'] = get_priority_val(user_input, ['pace'], {'pace': map_pace_drop})\n",
    "\n",
    "    # 2. PRIORITY OVERWRITE FEATURES\n",
    "    # Strike Pattern > Pace\n",
    "    prio_strike = ['strike_pattern', 'pace']\n",
    "    feats['strike_heel'] = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 1.0, 'Mid': 0.5, 'Forefoot': 0.0}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}})\n",
    "    feats['strike_mid'] = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 0.5, 'Mid': 1.0, 'Forefoot': 0.5}, 'pace': {'Easy': 0.5, 'Steady': 1.0, 'Fast': 0.5}})\n",
    "    feats['strike_forefoot'] = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 0.0, 'Mid': 0.0, 'Forefoot': 1.0}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}})\n",
    "\n",
    "    # Cushion > Pace\n",
    "    prio_soft = ['cushion_preferences', 'pace']\n",
    "    feats['softness_soft'] = get_priority_val(user_input, prio_soft, {'cushion_preferences': {'Soft': 1.0, 'Balanced': 0.5, 'Firm': 0.0}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}})\n",
    "    feats['softness_balanced'] = get_priority_val(user_input, prio_soft, {'cushion_preferences': {'Soft': 0.5, 'Balanced': 1.0, 'Firm': 0.5}, 'pace': {'Easy': 0.5, 'Steady': 1.0, 'Fast': 0.0}})\n",
    "    feats['softness_firm'] = get_priority_val(user_input, prio_soft, {'cushion_preferences': {'Soft': 0.0, 'Balanced': 0.5, 'Firm': 1.0}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}})\n",
    "\n",
    "    # Stability > Width\n",
    "    prio_width = ['stability_need', 'foot_width']\n",
    "    feats['width_narrow'] = get_priority_val(user_input, prio_width, {'stability_need': {'Neutral': 0.5, 'Guided': 1.0}, 'foot_width': {'Narrow': 1.0, 'Medium': 0.0, 'Wide': 0.0}})\n",
    "    feats['width_medium'] = get_priority_val(user_input, prio_width, {'stability_need': {'Neutral': 0.5, 'Guided': 0.5}, 'foot_width': {'Narrow': 0.5, 'Medium': 1.0, 'Wide': 0.0}})\n",
    "    feats['width_wide'] = get_priority_val(user_input, prio_width, {'stability_need': {'Neutral': 0.5, 'Guided': 0.0}, 'foot_width': {'Narrow': 0.0, 'Medium': 0.5, 'Wide': 1.0}})\n",
    "\n",
    "    # Toebox (Stability Only)\n",
    "    feats['toebox_narrow'] = get_priority_val(user_input, ['stability_need'], {'stability_need': {'Neutral': 0.5, 'Guided': 1.0}})\n",
    "    feats['toebox_medium'] = get_priority_val(user_input, ['stability_need'], {'stability_need': {'Neutral': 0.5, 'Guided': 0.5}})\n",
    "    feats['toebox_wide']   = get_priority_val(user_input, ['stability_need'], {'stability_need': {'Neutral': 0.5, 'Guided': 0.0}})\n",
    "\n",
    "    # Stiffness: Arch > Pace > Purpose\n",
    "    prio_stiff = ['arch_type', 'pace', 'running_purpose']\n",
    "    feats['stiffness_flexible'] = get_priority_val(user_input, prio_stiff, {'arch_type': {'Low': 0.0, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}, 'running_purpose': {'Daily': 1.0, 'Tempo': 0.5, 'Race': 0.0}})\n",
    "    feats['stiffness_moderate'] = get_priority_val(user_input, prio_stiff, {'arch_type': {'Low': 1.0, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 0.5, 'Steady': 1.0, 'Fast': 0.5}, 'running_purpose': {'Daily': 0.5, 'Tempo': 1.0, 'Race': 0.5}})\n",
    "    feats['stiffness_stiff'] = get_priority_val(user_input, prio_stiff, {'arch_type': {'Low': 1.0, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}, 'running_purpose': {'Daily': 0.0, 'Tempo': 0.5, 'Race': 1.0}})\n",
    "\n",
    "    # Torsional: Arch > Pace\n",
    "    prio_tor = ['arch_type', 'pace']\n",
    "    feats['torsional_flexible'] = get_priority_val(user_input, prio_tor, {'arch_type': {'Low': 0.0, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}})\n",
    "    feats['torsional_moderate'] = get_priority_val(user_input, prio_tor, {'arch_type': {'Low': 0.5, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 0.5, 'Steady': 1.0, 'Fast': 0.5}})\n",
    "    feats['torsional_stiff'] = get_priority_val(user_input, prio_tor, {'arch_type': {'Low': 1.0, 'Neutral': 0.5, 'High': 0.5}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}})\n",
    "\n",
    "    # Heel Stiff (Arch Only)\n",
    "    feats['heel_stiff_flexible'] = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 0.0, 'Neutral': 0.5, 'High': 1.0}})\n",
    "    feats['heel_stiff_moderate'] = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 0.5, 'Neutral': 1.0, 'High': 1.0}})\n",
    "    feats['heel_stiff_stiff']    = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 1.0, 'Neutral': 0.5, 'High': 0.0}})\n",
    "\n",
    "    # Plate: Pace > Purpose\n",
    "    prio_plate = ['pace', 'running_purpose']\n",
    "    feats['plate_rock'] = get_priority_val(user_input, prio_plate, {'pace': {'Easy': 0.5, 'Steady': 0.5, 'Fast': 0.5}, 'running_purpose': {'Daily': 0.5, 'Tempo': 0.5, 'Race': 0.5}})\n",
    "    feats['plate_carbon'] = get_priority_val(user_input, prio_plate, {'pace': {'Easy': 0.5, 'Steady': 0.5, 'Fast': 1.0}, 'running_purpose': {'Daily': 0.5, 'Tempo': 0.5, 'Race': 1.0}})\n",
    "\n",
    "    # Stack Height: Strike > Pace > Purpose\n",
    "    prio_stack = ['strike_pattern', 'pace', 'running_purpose']\n",
    "    feats['heel_lab_mm'] = get_priority_val(user_input, prio_stack, {'strike_pattern': {'Heel': 1.0, 'Mid': 0.5, 'Forefoot': 0.0}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}, 'running_purpose': {'Daily': 1.0, 'Tempo': 0.5, 'Race': 0.5}})\n",
    "    feats['forefoot_lab_mm'] = get_priority_val(user_input, prio_stack, {'strike_pattern': {'Heel': 0.0, 'Mid': 0.5, 'Forefoot': 1.0}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}, 'running_purpose': {'Daily': 1.0, 'Tempo': 0.5, 'Race': 0.5}})\n",
    "\n",
    "    # Weight (Invers Lightweight) & Defaults\n",
    "    feats['weight_lab_oz'] = 1.0 - feats['lightweight']\n",
    "    feats['toebox_durability'] = 1.0\n",
    "    feats['heel_durability'] = 1.0\n",
    "    feats['outsole_durability'] = 1.0\n",
    "    feats['breathability'] = 1.0\n",
    "\n",
    "    # Seasons\n",
    "    seasons = user_input.get('season', [])\n",
    "    has_summer = 1.0 if 'Summer' in seasons else 0.0\n",
    "    has_winter = 1.0 if 'Winter' in seasons else 0.0\n",
    "    has_all    = 1.0 if 'All' in seasons else 0.0\n",
    "    feats['season_summer'] = max(has_summer*1.0, has_winter*0.0, has_all*0.5)\n",
    "    feats['season_winter'] = max(has_summer*0.0, has_winter*1.0, has_all*0.5)\n",
    "    feats['season_all']    = max(has_summer*0.5, has_winter*0.5, has_all*1.0)\n",
    "    \n",
    "    # 3. MASKING LOGIC (Hanya ambil fitur yang diisi)\n",
    "    provided_inputs = {k for k, v in user_input.items() if v}\n",
    "    \n",
    "    # Dependency Map: Input apa menyalakan Fitur apa\n",
    "    feature_sources = {\n",
    "        'lightweight': ['pace'], 'rocker': ['running_purpose'],\n",
    "        'orthotic_friendly': ['orthotic_usage'], 'removable_insole': ['orthotic_usage'],\n",
    "        'pace_daily_running': ['running_purpose'], 'pace_tempo': ['running_purpose'], 'pace_competition': ['running_purpose'],\n",
    "        'arch_neutral': ['arch_type'], 'arch_stability': ['arch_type'],\n",
    "        'drop_lab_mm': ['pace'],\n",
    "        'strike_heel': ['strike_pattern', 'pace'], 'strike_mid': ['strike_pattern', 'pace'], 'strike_forefoot': ['strike_pattern', 'pace'],\n",
    "        'softness_soft': ['cushion_preferences', 'pace'], 'softness_balanced': ['cushion_preferences', 'pace'], 'softness_firm': ['cushion_preferences', 'pace'],\n",
    "        'width_narrow': ['stability_need', 'foot_width'], 'width_medium': ['stability_need', 'foot_width'], 'width_wide': ['stability_need', 'foot_width'],\n",
    "        'toebox_narrow': ['stability_need'], 'toebox_medium': ['stability_need'], 'toebox_wide': ['stability_need'],\n",
    "        'stiffness_flexible': ['arch_type', 'pace', 'running_purpose'], 'stiffness_moderate': ['arch_type', 'pace', 'running_purpose'], 'stiffness_stiff': ['arch_type', 'pace', 'running_purpose'],\n",
    "        'torsional_flexible': ['arch_type', 'pace'], 'torsional_moderate': ['arch_type', 'pace'], 'torsional_stiff': ['arch_type', 'pace'],\n",
    "        'heel_stiff_flexible': ['arch_type'], 'heel_stiff_moderate': ['arch_type'], 'heel_stiff_stiff': ['arch_type'],\n",
    "        'plate_rock': ['pace', 'running_purpose'], 'plate_carbon': ['pace', 'running_purpose'],\n",
    "        'heel_lab_mm': ['strike_pattern', 'pace', 'running_purpose'], 'forefoot_lab_mm': ['strike_pattern', 'pace', 'running_purpose'],\n",
    "        'weight_lab_oz': ['pace'],\n",
    "        'season_summer': ['season'], 'season_winter': ['season'], 'season_all': ['season'],\n",
    "        # Default Features (selalu ignore di similarity kecuali diminta khusus)\n",
    "        'toebox_durability': [], 'heel_durability': [], 'outsole_durability': [], 'breathability': []\n",
    "    }\n",
    "    \n",
    "    # Susun Vector Lengkap\n",
    "    all_cols = binary_cols + continuous_cols\n",
    "    full_vector_raw = []\n",
    "    for col in binary_cols:\n",
    "        full_vector_raw.append(feats.get(col, 0.0))\n",
    "    for col in continuous_cols:\n",
    "        full_vector_raw.append(feats.get(col, 0.5))\n",
    "\n",
    "    # Tentukan Index Valid\n",
    "    valid_indices = []\n",
    "    for i, col in enumerate(all_cols):\n",
    "        sources = feature_sources.get(col, [])\n",
    "        if any(src in provided_inputs for src in sources):\n",
    "            valid_indices.append(i)\n",
    "            \n",
    "    # Jika tidak ada input sama sekali, pakai semua (fallback)\n",
    "    if not valid_indices:\n",
    "        valid_indices = list(range(len(all_cols)))\n",
    "        \n",
    "    return full_vector_raw, valid_indices\n",
    "\n",
    "# --- RECOMMENDER MAIN FUNCTION ---\n",
    "def recommend_shoes_deep_masked(user_input, df_data, encoder_model, kmeans_model, binary_cols, continuous_cols, X_combined_data):\n",
    "    # 1. Preprocess & Get Mask\n",
    "    full_vector, valid_idx = preprocess_user_input_with_mask(user_input, binary_cols, continuous_cols)\n",
    "    full_vector = np.array([full_vector])\n",
    "\n",
    "    # 2. Clustering (Pakai Vector Lengkap dengan asumsi netral)\n",
    "    user_latent = encoder_model.predict(full_vector, verbose=0)\n",
    "    distances = kmeans_model.transform(user_latent)[0]\n",
    "    n_select = math.ceil(kmeans_model.n_clusters / 3)\n",
    "    closest_clusters = np.argsort(distances)[:n_select]\n",
    "    \n",
    "    print(f\"User mapped to Clusters: {closest_clusters}\")\n",
    "    \n",
    "    # 3. Filter Candidates\n",
    "    candidates = df_data[df_data['cluster'].isin(closest_clusters)].copy()\n",
    "    if candidates.empty: return pd.DataFrame()\n",
    "    \n",
    "    # 4. Masked Scoring (Hanya fitur yang relevan)\n",
    "    candidate_vectors = X_combined_data[candidates.index]\n",
    "    \n",
    "    # Slicing Vector\n",
    "    user_vec_masked = full_vector[:, valid_idx]\n",
    "    cand_vecs_masked = candidate_vectors[:, valid_idx]\n",
    "    \n",
    "    # Hitung Similarity\n",
    "    if np.all(user_vec_masked == 0):\n",
    "        scores = np.zeros(len(candidates))\n",
    "    else:\n",
    "        scores = cosine_similarity(user_vec_masked, cand_vecs_masked)[0]\n",
    "    \n",
    "    # 5. Result\n",
    "    candidates['match_score'] = scores\n",
    "    cols_show = ['brand', 'name', 'match_score', 'cluster', 'price']\n",
    "    cols_show = [c for c in cols_show if c in candidates.columns]\n",
    "    \n",
    "    return candidates.sort_values('match_score', ascending=False).head(10)[cols_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dceba",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4bb1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULAI PENGUJIAN RANDOM ===\n",
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #1: User mengisi 3 fitur\n",
      "Input User:\n",
      "{'cushion_preferences': 'Balanced', 'orthotic_usage': 'No', 'season': ['Winter']}\n",
      "User mapped to Clusters: [1 2]\n",
      "\n",
      "Top 10 Rekomendasi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>asics</td>\n",
       "      <td>dynablast 4</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>on</td>\n",
       "      <td>cloudrunner 2 waterproof</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>adidas</td>\n",
       "      <td>runfalcon</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>under armour</td>\n",
       "      <td>slipspeed mega</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>under armour</td>\n",
       "      <td>hovr phantom 3</td>\n",
       "      <td>0.784465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>altra</td>\n",
       "      <td>via olympus</td>\n",
       "      <td>0.693375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>under armour</td>\n",
       "      <td>charged pursuit 3</td>\n",
       "      <td>0.693375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>asics</td>\n",
       "      <td>dynablast 3</td>\n",
       "      <td>0.693375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>adidas</td>\n",
       "      <td>ultrarun 5</td>\n",
       "      <td>0.693375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>asics</td>\n",
       "      <td>versablast 4</td>\n",
       "      <td>0.693375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand                      name  match_score  cluster\n",
       "88          asics               dynablast 4     0.832050        1\n",
       "73             on  cloudrunner 2 waterproof     0.832050        1\n",
       "340        adidas                 runfalcon     0.832050        2\n",
       "352  under armour            slipspeed mega     0.832050        1\n",
       "224  under armour            hovr phantom 3     0.784465        1\n",
       "400         altra               via olympus     0.693375        1\n",
       "57   under armour         charged pursuit 3     0.693375        1\n",
       "87          asics               dynablast 3     0.693375        1\n",
       "394        adidas                ultrarun 5     0.693375        1\n",
       "399         asics              versablast 4     0.693375        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #2: User mengisi 6 fitur\n",
      "Input User:\n",
      "{'foot_width': 'Narrow', 'season': ['Summer'], 'stability_need': 'Neutral', 'strike_pattern': 'Heel', 'running_purpose': 'Tempo', 'pace': 'Easy'}\n",
      "User mapped to Clusters: [3 1]\n",
      "\n",
      "Top 10 Rekomendasi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>adidas</td>\n",
       "      <td>pureboost 23</td>\n",
       "      <td>0.751961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>new balance</td>\n",
       "      <td>fuelcell rebel v3</td>\n",
       "      <td>0.730992</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>adidas</td>\n",
       "      <td>ultraboost 1.0</td>\n",
       "      <td>0.718455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>nike</td>\n",
       "      <td>zoomx streakfly</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adidas</td>\n",
       "      <td>adizero adios 8</td>\n",
       "      <td>0.712919</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>nike</td>\n",
       "      <td>streakfly 2</td>\n",
       "      <td>0.707732</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>nike</td>\n",
       "      <td>pegasus 41</td>\n",
       "      <td>0.702017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>brooks</td>\n",
       "      <td>hyperion gts</td>\n",
       "      <td>0.694504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>saucony</td>\n",
       "      <td>tempus</td>\n",
       "      <td>0.693901</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>saucony</td>\n",
       "      <td>endorphin speed 5</td>\n",
       "      <td>0.688695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand               name  match_score  cluster\n",
       "309       adidas       pureboost 23     0.751961        1\n",
       "149  new balance  fuelcell rebel v3     0.730992        3\n",
       "387       adidas     ultraboost 1.0     0.718455        1\n",
       "432         nike    zoomx streakfly     0.715878        3\n",
       "11        adidas    adizero adios 8     0.712919        3\n",
       "357         nike        streakfly 2     0.707732        3\n",
       "297         nike         pegasus 41     0.702017        1\n",
       "233       brooks       hyperion gts     0.694504        3\n",
       "373      saucony             tempus     0.693901        3\n",
       "102      saucony  endorphin speed 5     0.688695        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #3: User mengisi 9 fitur\n",
      "Input User:\n",
      "{'orthotic_usage': 'No', 'foot_width': 'Medium', 'season': ['Winter', 'All'], 'stability_need': 'Guided', 'strike_pattern': 'Forefoot', 'pace': 'Steady', 'arch_type': 'Low', 'running_purpose': 'Daily', 'cushion_preferences': 'Firm'}\n",
      "User mapped to Clusters: [1 2]\n",
      "\n",
      "Top 10 Rekomendasi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hoka</td>\n",
       "      <td>arahi 7</td>\n",
       "      <td>0.725267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>on</td>\n",
       "      <td>cloudrunner 2 waterproof</td>\n",
       "      <td>0.724211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>hoka</td>\n",
       "      <td>rincon 4</td>\n",
       "      <td>0.718362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>saucony</td>\n",
       "      <td>axon 2</td>\n",
       "      <td>0.702748</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hoka</td>\n",
       "      <td>clifton 9</td>\n",
       "      <td>0.701600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>asics</td>\n",
       "      <td>gel kayano 32</td>\n",
       "      <td>0.694434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>asics</td>\n",
       "      <td>gt 2000 14</td>\n",
       "      <td>0.693990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>asics</td>\n",
       "      <td>gt 2000 12</td>\n",
       "      <td>0.692990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>asics</td>\n",
       "      <td>gt 1000 13</td>\n",
       "      <td>0.692763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>on</td>\n",
       "      <td>cloudflyer 5</td>\n",
       "      <td>0.692352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand                      name  match_score  cluster\n",
       "42      hoka                   arahi 7     0.725267        1\n",
       "73        on  cloudrunner 2 waterproof     0.724211        1\n",
       "334     hoka                  rincon 4     0.718362        1\n",
       "48   saucony                    axon 2     0.702748        2\n",
       "61      hoka                 clifton 9     0.701600        2\n",
       "174    asics             gel kayano 32     0.694434        1\n",
       "219    asics                gt 2000 14     0.693990        1\n",
       "217    asics                gt 2000 12     0.692990        1\n",
       "212    asics                gt 1000 13     0.692763        1\n",
       "67        on              cloudflyer 5     0.692352        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Pengujian Selesai.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# --- 1. SETUP OPSI INPUT ---\n",
    "# Daftar kemungkinan jawaban untuk setiap input\n",
    "input_options = {\n",
    "    'running_purpose': ['Daily', 'Tempo', 'Race'],\n",
    "    'pace': ['Easy', 'Steady', 'Fast'],\n",
    "    'orthotic_usage': ['Yes', 'No'],\n",
    "    'arch_type': ['Low', 'Neutral', 'High'],\n",
    "    'strike_pattern': ['Heel', 'Mid', 'Forefoot'],\n",
    "    'cushion_preferences': ['Soft', 'Balanced', 'Firm'],\n",
    "    'foot_width': ['Narrow', 'Medium', 'Wide'],\n",
    "    'stability_need': ['Neutral', 'Guided'],\n",
    "    'season': [['Summer'], ['Winter'], ['All'], ['Summer', 'All'], ['Winter', 'All']]\n",
    "}\n",
    "\n",
    "def generate_random_user_input(num_features):\n",
    "    \"\"\"\n",
    "    Membuat dictionary input user dengan jumlah fitur acak tertentu.\n",
    "    \"\"\"\n",
    "    # Ambil semua key yang tersedia\n",
    "    all_keys = list(input_options.keys())\n",
    "    \n",
    "    # Pilih 'num_features' key secara acak\n",
    "    selected_keys = random.sample(all_keys, k=min(num_features, len(all_keys)))\n",
    "    \n",
    "    # Isi nilai untuk key yang terpilih\n",
    "    user_input = {}\n",
    "    for key in selected_keys:\n",
    "        user_input[key] = random.choice(input_options[key])\n",
    "        \n",
    "    return user_input\n",
    "\n",
    "# --- 2. GENERATE & RUN TEST CASES ---\n",
    "# Kita buat skenario jumlah input: 3, 6, dan 9 (Full)\n",
    "target_counts = [3, 6, 9]\n",
    "\n",
    "print(\"=== MULAI PENGUJIAN RANDOM ===\")\n",
    "\n",
    "for i, count in enumerate(target_counts):\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"TEST CASE #{i+1}: User mengisi {count} fitur\")\n",
    "    \n",
    "    # 1. Generate Input\n",
    "    random_input = generate_random_user_input(count)\n",
    "    print(f\"Input User:\\n{random_input}\")\n",
    "    \n",
    "    # 2. Jalankan Rekomendasi\n",
    "    # Pastikan variabel df, encoder, dll sudah ada dari cell sebelumnya\n",
    "    try:\n",
    "        recommendations = recommend_shoes_deep_masked(\n",
    "            random_input, \n",
    "            df, \n",
    "            encoder, \n",
    "            best_model, \n",
    "            binary_cols, \n",
    "            continuous_cols, \n",
    "            X_combined\n",
    "        )\n",
    "        \n",
    "        # 3. Tampilkan Hasil\n",
    "        if not recommendations.empty:\n",
    "            print(\"\\nTop 10 Rekomendasi:\")\n",
    "            # Tampilkan kolom yang relevan saja agar rapi\n",
    "            cols = ['brand', 'name', 'match_score', 'cluster']\n",
    "            display(recommendations.head(10)[cols])\n",
    "        else:\n",
    "            print(\"\\nTidak ada rekomendasi ditemukan (Cluster mungkin kosong).\")\n",
    "            \n",
    "    except NameError:\n",
    "        print(\"\\nERROR: Pastikan kode setup model dan fungsi 'recommend_shoes_deep_masked' sudah dijalankan sebelumnya.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "\n",
    "print(f\"\\n{'-'*60}\")\n",
    "print(\"Pengujian Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a509959",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb4fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models to: ../model_artifacts/road/v_20260207_093445\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Buat nama folder unik berdasarkan waktu sekarang\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"../model_artifacts/road/v_{timestamp}\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"Saving models to: {save_dir}\")\n",
    "\n",
    "# 2. Simpan file dengan nama STANDAR di dalam folder tersebut\n",
    "# Perhatikan: Nama file TIDAK pakai tanggal, foldernya yang pakai.\n",
    "encoder.save(f'{save_dir}/shoe_encoder.keras')\n",
    "\n",
    "with open(f'{save_dir}/kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "df.to_pickle(f'{save_dir}/shoe_metadata.pkl')\n",
    "\n",
    "with open(f'{save_dir}/shoe_features.pkl', 'wb') as f:\n",
    "    pickle.dump(X_combined, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
