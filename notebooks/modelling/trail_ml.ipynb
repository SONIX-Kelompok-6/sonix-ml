{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cdf0b4",
   "metadata": {},
   "source": [
    "# Import Library & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37034b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n",
      "Time: 2026-02-10 09:01:10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# ML\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('Libraries loaded')\n",
    "print(f'Time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409bb62",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ac2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 158 shoes × 33 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>terrain_light</th>\n",
       "      <th>terrain_moderate</th>\n",
       "      <th>terrain_technical</th>\n",
       "      <th>shock_absorption</th>\n",
       "      <th>energy_return</th>\n",
       "      <th>arch_neutral</th>\n",
       "      <th>arch_stability</th>\n",
       "      <th>weight_lab_oz</th>\n",
       "      <th>...</th>\n",
       "      <th>heel_stiff</th>\n",
       "      <th>lug_dept_mm</th>\n",
       "      <th>heel_lab_mm</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>season_all</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex agravic speed ultra</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex speed ultra</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>34.5</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild 2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>altra</td>\n",
       "      <td>lone peak 5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                        name  terrain_light  terrain_moderate  \\\n",
       "0  adidas  terrex agravic speed ultra              1                 0   \n",
       "1  adidas          terrex speed ultra              1                 0   \n",
       "2   altra             experience wild              1                 1   \n",
       "3   altra           experience wild 2              1                 0   \n",
       "4   altra               lone peak 5.0              1                 1   \n",
       "\n",
       "   terrain_technical  shock_absorption  energy_return  arch_neutral  \\\n",
       "0                  0                 3              5             1   \n",
       "1                  0                 0              0             1   \n",
       "2                  0                 3              1             1   \n",
       "3                  0                 3              1             1   \n",
       "4                  0                 0              0             1   \n",
       "\n",
       "   arch_stability  weight_lab_oz  ...  heel_stiff  lug_dept_mm  heel_lab_mm  \\\n",
       "0               0            9.1  ...           1          2.5         30.6   \n",
       "1               0            9.1  ...           1          2.6         32.8   \n",
       "2               0           10.1  ...           3          3.6         34.5   \n",
       "3               0            9.4  ...           1          3.5         32.3   \n",
       "4               0           10.7  ...           0          3.7         24.5   \n",
       "\n",
       "   forefoot_lab_mm  season_summer  season_winter  season_all  \\\n",
       "0             30.3              0              0           1   \n",
       "1             24.6              0              0           0   \n",
       "2             30.2              0              0           1   \n",
       "3             26.2              0              0           1   \n",
       "4             24.3              0              0           0   \n",
       "\n",
       "   removable_insole  waterproof  water_repellent  \n",
       "0                 1           0                0  \n",
       "1                 1           0                0  \n",
       "2                 1           0                0  \n",
       "3                 1           0                0  \n",
       "4                 1           0                0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = '../../data/trail_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Loaded: {df.shape[0]} shoes × {df.shape[1]} columns')\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"WARNING: '{file}' not found.\")\n",
    "    print(\"Please upload the correct dataset file to run with actual data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b87ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 33 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   brand               158 non-null    str    \n",
      " 1   name                158 non-null    str    \n",
      " 2   terrain_light       158 non-null    int64  \n",
      " 3   terrain_moderate    158 non-null    int64  \n",
      " 4   terrain_technical   158 non-null    int64  \n",
      " 5   shock_absorption    158 non-null    int64  \n",
      " 6   energy_return       158 non-null    int64  \n",
      " 7   arch_neutral        158 non-null    int64  \n",
      " 8   arch_stability      158 non-null    int64  \n",
      " 9   weight_lab_oz       158 non-null    float64\n",
      " 10  drop_lab_mm         158 non-null    float64\n",
      " 11  strike_heel         158 non-null    int64  \n",
      " 12  strike_mid          158 non-null    int64  \n",
      " 13  strike_forefoot     158 non-null    int64  \n",
      " 14  midsole_softness    158 non-null    int64  \n",
      " 15  toebox_durability   158 non-null    int64  \n",
      " 16  heel_durability     158 non-null    int64  \n",
      " 17  outsole_durability  158 non-null    int64  \n",
      " 18  plate_rock_plate    158 non-null    int64  \n",
      " 19  plate_carbon_plate  158 non-null    int64  \n",
      " 20  width_fit           158 non-null    int64  \n",
      " 21  toebox_width        158 non-null    int64  \n",
      " 22  torsional_rigidity  158 non-null    int64  \n",
      " 23  heel_stiff          158 non-null    int64  \n",
      " 24  lug_dept_mm         158 non-null    float64\n",
      " 25  heel_lab_mm         158 non-null    float64\n",
      " 26  forefoot_lab_mm     158 non-null    float64\n",
      " 27  season_summer       158 non-null    int64  \n",
      " 28  season_winter       158 non-null    int64  \n",
      " 29  season_all          158 non-null    int64  \n",
      " 30  removable_insole    158 non-null    int64  \n",
      " 31  waterproof          158 non-null    int64  \n",
      " 32  water_repellent     158 non-null    int64  \n",
      "dtypes: float64(5), int64(26), str(2)\n",
      "memory usage: 40.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0f9b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44420bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 31 total\n",
      "  Binary     : 16\n",
      "  Continuous : 15\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "binary_cols = [col for col in numeric_cols if set(df[col].unique()).issubset({0, 1})]\n",
    "continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "\n",
    "print(f'Features: {len(numeric_cols)} total')\n",
    "print(f'  Binary     : {len(binary_cols)}')\n",
    "print(f'  Continuous : {len(continuous_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d852a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural input shape: (158, 31)\n",
      "Range: [0.000000, 1.000000]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = numeric_cols.copy()\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Separate for proper scaling\n",
    "X_binary = X[binary_cols].values\n",
    "X_continuous = X[continuous_cols].values\n",
    "\n",
    "# Scale continuous to 0-1 for neural network\n",
    "scaler_continuous = MinMaxScaler()\n",
    "X_continuous_scaled = scaler_continuous.fit_transform(X_continuous)\n",
    "\n",
    "# Combine\n",
    "X_combined = np.concatenate([X_binary, X_continuous_scaled], axis=1)\n",
    "\n",
    "# Also standard scaling for traditional comparison\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print(f'Neural input shape: {X_combined.shape}')\n",
    "print(f'Range: [{X_combined.min():.6f}, {X_combined.max():.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77513e",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b73e33",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2eb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,023</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │         \u001b[38;5;34m1,023\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,815</span> (14.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,815\u001b[0m (14.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,607</span> (14.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,607\u001b[0m (14.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> (832.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m208\u001b[0m (832.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Architecture\n",
    "input_dim = X_combined.shape[1]\n",
    "encoding_dims = [32, 16, 8]\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = input_layer\n",
    "for dim in encoding_dims:\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "latent = x\n",
    "\n",
    "# Decoder\n",
    "for dim in reversed(encoding_dims[:-1]):\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "encoder = Model(input_layer, latent)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print('Autoencoder architecture:')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaab33",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6fb0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Final loss: 0.072080\n",
      "  Val loss: 0.097575\n",
      "Latent space: (158, 8) (8D embeddings)\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_combined, X_combined,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f'Training done!')\n",
    "print(f'Final loss: {history.history[\"loss\"][-1]:.6f}')\n",
    "print(f'  Val loss: {history.history[\"val_loss\"][-1]:.6f}')\n",
    "\n",
    "# Get latent representations\n",
    "X_latent = encoder.predict(X_combined, verbose=0)\n",
    "print(f'Latent space: {X_latent.shape} (8D embeddings)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb6321",
   "metadata": {},
   "source": [
    "# Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601dd47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions ready\n"
     ]
    }
   ],
   "source": [
    "def calculate_cluster_purity(df, cluster_col, binary_cols):\n",
    "    \"\"\"\n",
    "    Calculates the purity of each cluster based on binary features.\n",
    "    Purity is defined as the mean dominance of the most frequent value (0 or 1)\n",
    "    within each binary column for a given cluster.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'by_cluster': A dictionary with purity and count for each cluster.\n",
    "            - 'mean_purity': The average purity across all clusters.\n",
    "            - 'min_purity': The minimum purity among all clusters.\n",
    "            - 'max_purity': The maximum purity among all clusters.\n",
    "    \"\"\"\n",
    "    purity_by_cluster = {}\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        dominances = []\n",
    "        for col in binary_cols:\n",
    "            if col in cdata.columns:\n",
    "                vc = cdata[col].value_counts()\n",
    "                if len(vc) > 0:\n",
    "                    dominances.append(vc.max() / n)\n",
    "        purity_by_cluster[cid] = {'purity': np.mean(dominances) if dominances else 0, 'n': n}\n",
    "    all_p = [v['purity'] for v in purity_by_cluster.values()]\n",
    "    return {\n",
    "        'by_cluster': purity_by_cluster,\n",
    "        'mean_purity': np.mean(all_p),\n",
    "        'min_purity': np.min(all_p),\n",
    "        'max_purity': np.max(all_p)\n",
    "    }\n",
    "\n",
    "def calculate_cluster_stability(X, labels, model_func, n_iter=20):\n",
    "    \"\"\"\n",
    "    Calculates the stability of clustering using the Adjusted Rand Index (ARI).\n",
    "    It performs bootstrapping by re-sampling the data and re-clustering to measure\n",
    "    how consistent the cluster assignments are.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The original cluster labels from the initial clustering.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (e.g., `lambda: KMeans(n_clusters=k)`).\n",
    "        n_iter (int, optional): The number of bootstrap iterations. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_ari': The mean Adjusted Rand Index.\n",
    "            - 'std_ari': The standard deviation of the ARI scores.\n",
    "            - 'stability_level': A categorical label (Excellent, Good, Moderate)\n",
    "                                 based on the mean ARI.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    ari_scores = []\n",
    "    for _ in range(n_iter):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        # Ensure model_func returns a new, untrained model each time\n",
    "        boot_model = model_func()\n",
    "        boot_labels = boot_model.fit_predict(X[idx])\n",
    "        ari = adjusted_rand_score(labels[idx], boot_labels)\n",
    "        ari_scores.append(ari)\n",
    "    m = np.mean(ari_scores)\n",
    "    return {\n",
    "        'mean_ari': m,\n",
    "        'std_ari': np.std(ari_scores),\n",
    "        'stability_level': 'Excellent' if m > 0.8 else 'Good' if m > 0.6 else 'Moderate'\n",
    "    }\n",
    "\n",
    "def calculate_interpretability_score(df, cluster_col, binary_cols, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Calculates an interpretability score for each cluster.\n",
    "    A cluster is considered more interpretable if a high proportion of its members\n",
    "    strongly exhibit (or strongly do not exhibit) certain binary features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing data and cluster assignments.\n",
    "        cluster_col (str): The name of the column in df that contains cluster labels.\n",
    "        binary_cols (list): A list of column names in df that are binary features.\n",
    "        threshold (float, optional): The threshold for defining strong exhibition.\n",
    "                                     A feature is 'strong' if its mean in a cluster\n",
    "                                     is > threshold or < (1 - threshold). Defaults to 0.75.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'mean_interpretability': The average interpretability score across all clusters.\n",
    "            - 'scores': A list of interpretability scores for each cluster.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for cid in df[cluster_col].unique():\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        strong = sum(1 for col in binary_cols if col in cdata.columns and\n",
    "                    (cdata[col].sum()/n > threshold or cdata[col].sum()/n < 1-threshold))\n",
    "        # Score is the proportion of binary features that are 'strong' for this cluster\n",
    "        scores.append(strong / len(binary_cols))\n",
    "    return {'mean_interpretability': np.mean(scores), 'scores': scores}\n",
    "\n",
    "def evaluate_clustering_comprehensive(X, labels, df_temp, model_func, binary_cols):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive evaluation of clustering results using multiple metrics.\n",
    "    It calculates Silhouette, Davies-Bouldin, Calinski-Harabasz scores, as well as\n",
    "    custom purity, stability, and interpretability scores.\n",
    "    A composite score is then calculated based on a weighted average of normalized metrics.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix used for clustering.\n",
    "        labels (np.ndarray): The cluster labels generated by the clustering algorithm.\n",
    "        df_temp (pd.DataFrame): A temporary DataFrame, copy of the original, to add cluster labels.\n",
    "        model_func (callable): A function that returns a new, untrained clustering model\n",
    "                                (used for stability calculation).\n",
    "        binary_cols (list): A list of column names in df_temp that are binary features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing various evaluation metrics and a composite score:\n",
    "            - 'silhouette': Silhouette Score.\n",
    "            - 'davies_bouldin': Davies-Bouldin Score.\n",
    "            - 'calinski_harabasz': Calinski-Harabasz Score.\n",
    "            - 'purity': Mean cluster purity.\n",
    "            - 'stability': Mean Adjusted Rand Index from stability testing.\n",
    "            - 'interpretability': Mean cluster interpretability score.\n",
    "            - 'composite_score': A weighted composite score of normalized metrics.\n",
    "    \"\"\"\n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    df_temp['cluster'] = labels\n",
    "    purity = calculate_cluster_purity(df_temp, 'cluster', binary_cols)\n",
    "    stability = calculate_cluster_stability(X, labels, model_func, 10)\n",
    "    interp = calculate_interpretability_score(df_temp, 'cluster', binary_cols)\n",
    "\n",
    "    # Normalize scores for composite calculation\n",
    "    sil_norm = (sil + 1) / 2\n",
    "    db_norm = 1 / (1 + db)\n",
    "    ch_norm = min(ch / 1000, 1)\n",
    "\n",
    "    # Composite score with example weights\n",
    "    composite = (0.25*sil_norm + 0.20*db_norm + 0.15*ch_norm +\n",
    "                 0.25*purity['mean_purity'] + 0.10*stability['mean_ari'] +\n",
    "                 0.05*interp['mean_interpretability'])\n",
    "\n",
    "    return {\n",
    "        'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch,\n",
    "        'purity': purity['mean_purity'], 'stability': stability['mean_ari'],\n",
    "        'interpretability': interp['mean_interpretability'], 'composite_score': composite\n",
    "    }\n",
    "\n",
    "print('Metrics functions ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ba812",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1f4985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  K  |  Score   |   Sil.   |    DB    |     CH     |  Purity  |  Stab.   |  Interp  |\n",
      "|-----+----------+----------+----------+------------+----------+----------+----------|\n",
      "|  3  | 0.666632 | 0.494526 | 0.833814 | 120.914306 | 0.865731 | 0.966011 | 0.791667 |\n",
      "|  4  | 0.672299 | 0.490555 | 0.760047 | 135.967871 | 0.863977 | 0.953318 | 0.812500 |\n",
      "|  5  | 0.635842 | 0.367890 | 0.929490 | 126.544045 | 0.878209 | 0.820421 | 0.812500 |\n",
      "|  6  | 0.640412 | 0.367252 | 0.925535 | 119.559908 | 0.894479 | 0.818965 | 0.843750 |\n",
      "|  7  | 0.630861 | 0.377165 | 1.012078 | 117.873501 | 0.887777 | 0.777265 | 0.839286 |\n",
      "|  8  | 0.629461 | 0.369986 | 0.999311 | 116.258834 | 0.897214 | 0.765927 | 0.796875 |\n",
      "|  9  | 0.640633 | 0.374334 | 0.978029 | 116.685722 | 0.899664 | 0.843398 | 0.819444 |\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Header Tabel\n",
    "print(f\"| {'K':^3} | {'Score':^8} | {'Sil.':^8} | {'DB':^8} | {'CH':^10} | {'Purity':^8} | {'Stab.':^8} | {'Interp':^8} |\")\n",
    "print(f\"|{'-'*5}+{'-'*10}+{'-'*10}+{'-'*10}+{'-'*12}+{'-'*10}+{'-'*10}+{'-'*10}|\")\n",
    "\n",
    "for i in range(3, 10):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    model_factory = lambda: KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "    model = model_factory()\n",
    "    labels = model.fit_predict(X_latent)\n",
    "\n",
    "    metrics = evaluate_clustering_comprehensive(\n",
    "        X_latent, labels, df.copy(),\n",
    "        model_factory,\n",
    "        binary_cols\n",
    "    )\n",
    "\n",
    "    # Simpan hasil\n",
    "    results.append({\n",
    "        'k': i,\n",
    "        'model': model,\n",
    "        'labels': labels,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "    # Print Baris Tabel\n",
    "    print(f\"| {i:^3} | {metrics['composite_score']:<8.6f} | {metrics['silhouette']:<6.6f} | \"\n",
    "          f\"{metrics['davies_bouldin']:<6.6f} | {metrics['calinski_harabasz']:<8.6f} | \"\n",
    "          f\"{metrics['purity']:<6.6f} | {metrics['stability']:<6.6f} | {metrics['interpretability']:<6.6f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa23de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED BEST K: 4\n",
      "   Silhouette      : 0.490555\n",
      "   Composite Score : 0.672299\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "best_config = df_results.loc[df_results['composite_score'].idxmax()]\n",
    "\n",
    "best_model = best_config['model']\n",
    "best_labels = best_config['labels']\n",
    "best_k = best_config['k']\n",
    "X_for_clustering = X_latent\n",
    "\n",
    "print(f'SELECTED BEST K: {best_k}')\n",
    "print(f'   Silhouette      : {best_config[\"silhouette\"]:.6f}')\n",
    "print(f'   Composite Score : {best_config[\"composite_score\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedd13e",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb087b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('float64').columns.tolist():\n",
    "    new_col_name = col + '_bin'\n",
    "    df[new_col_name] = pd.qcut(df[col], q=3, labels=[0, 0.5, 1]).astype(int)\n",
    "\n",
    "# Reorder columns: non-numeric, binary, then continuous with their bins, then cluster\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "new_column_order = []\n",
    "\n",
    "# non-numeric columns\n",
    "for col in non_numeric_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# binary columns\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "# continuous columns and their corresponding bin columns\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "    bin_col_name = col + '_bin'\n",
    "    if bin_col_name in df.columns:\n",
    "        new_column_order.append(bin_col_name)\n",
    "\n",
    "# Add the 'cluster' column\n",
    "if 'cluster' in df.columns and 'cluster' not in new_column_order:\n",
    "    new_column_order.append('cluster')\n",
    "\n",
    "# Reindex the DataFrame with the new order\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e638024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   brand                158 non-null    str    \n",
      " 1   name                 158 non-null    str    \n",
      " 2   terrain_light        158 non-null    int64  \n",
      " 3   terrain_moderate     158 non-null    int64  \n",
      " 4   terrain_technical    158 non-null    int64  \n",
      " 5   arch_neutral         158 non-null    int64  \n",
      " 6   arch_stability       158 non-null    int64  \n",
      " 7   strike_heel          158 non-null    int64  \n",
      " 8   strike_mid           158 non-null    int64  \n",
      " 9   strike_forefoot      158 non-null    int64  \n",
      " 10  plate_rock_plate     158 non-null    int64  \n",
      " 11  plate_carbon_plate   158 non-null    int64  \n",
      " 12  season_summer        158 non-null    int64  \n",
      " 13  season_winter        158 non-null    int64  \n",
      " 14  season_all           158 non-null    int64  \n",
      " 15  removable_insole     158 non-null    int64  \n",
      " 16  waterproof           158 non-null    int64  \n",
      " 17  water_repellent      158 non-null    int64  \n",
      " 18  shock_absorption     158 non-null    int64  \n",
      " 19  energy_return        158 non-null    int64  \n",
      " 20  weight_lab_oz        158 non-null    float64\n",
      " 21  weight_lab_oz_bin    158 non-null    int64  \n",
      " 22  drop_lab_mm          158 non-null    float64\n",
      " 23  drop_lab_mm_bin      158 non-null    int64  \n",
      " 24  midsole_softness     158 non-null    int64  \n",
      " 25  toebox_durability    158 non-null    int64  \n",
      " 26  heel_durability      158 non-null    int64  \n",
      " 27  outsole_durability   158 non-null    int64  \n",
      " 28  width_fit            158 non-null    int64  \n",
      " 29  toebox_width         158 non-null    int64  \n",
      " 30  torsional_rigidity   158 non-null    int64  \n",
      " 31  heel_stiff           158 non-null    int64  \n",
      " 32  lug_dept_mm          158 non-null    float64\n",
      " 33  lug_dept_mm_bin      158 non-null    int64  \n",
      " 34  heel_lab_mm          158 non-null    float64\n",
      " 35  heel_lab_mm_bin      158 non-null    int64  \n",
      " 36  forefoot_lab_mm      158 non-null    float64\n",
      " 37  forefoot_lab_mm_bin  158 non-null    int64  \n",
      "dtypes: float64(5), int64(31), str(2)\n",
      "memory usage: 47.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84409589",
   "metadata": {},
   "source": [
    "# Generate Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58df965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>shock_absorption</th>\n",
       "      <th>energy_return</th>\n",
       "      <th>weight_lab_oz</th>\n",
       "      <th>drop_lab_mm</th>\n",
       "      <th>midsole_softness</th>\n",
       "      <th>toebox_durability</th>\n",
       "      <th>heel_durability</th>\n",
       "      <th>outsole_durability</th>\n",
       "      <th>...</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>terrain</th>\n",
       "      <th>arch</th>\n",
       "      <th>strike</th>\n",
       "      <th>plate_rock_plate</th>\n",
       "      <th>plate_carbon_plate</th>\n",
       "      <th>season</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>57.6%</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.43</td>\n",
       "      <td>10.09</td>\n",
       "      <td>5.74</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.24</td>\n",
       "      <td>...</td>\n",
       "      <td>25.97</td>\n",
       "      <td>light (69%)</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (100%)</td>\n",
       "      <td>no (20%)</td>\n",
       "      <td>no (4%)</td>\n",
       "      <td>all (90%)</td>\n",
       "      <td>yes (95%)</td>\n",
       "      <td>no (7%)</td>\n",
       "      <td>no (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>21.5%</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.09</td>\n",
       "      <td>10.30</td>\n",
       "      <td>12.03</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.68</td>\n",
       "      <td>...</td>\n",
       "      <td>24.55</td>\n",
       "      <td>light (79%)</td>\n",
       "      <td>neutral (94%)</td>\n",
       "      <td>heel (100%)</td>\n",
       "      <td>no (18%)</td>\n",
       "      <td>no (12%)</td>\n",
       "      <td>all (79%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (18%)</td>\n",
       "      <td>no (3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>11.4%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.09</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.52</td>\n",
       "      <td>moderate (78%)</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (100%)</td>\n",
       "      <td>no (50%)</td>\n",
       "      <td>no (6%)</td>\n",
       "      <td>all (33%)</td>\n",
       "      <td>yes (67%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (6%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>9.5%</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>10.70</td>\n",
       "      <td>11.11</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>24.06</td>\n",
       "      <td>light (60%)</td>\n",
       "      <td>neutral (87%)</td>\n",
       "      <td>heel (93%)</td>\n",
       "      <td>no (13%)</td>\n",
       "      <td>no (13%)</td>\n",
       "      <td>all (53%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (7%)</td>\n",
       "      <td>no (0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count percentage  shock_absorption  energy_return  weight_lab_oz  \\\n",
       "0     91      57.6%              1.91           1.43          10.09   \n",
       "1     34      21.5%              1.97           1.09          10.30   \n",
       "2     18      11.4%              0.00           0.00          10.09   \n",
       "3     15       9.5%              0.40           0.13          10.70   \n",
       "\n",
       "   drop_lab_mm  midsole_softness  toebox_durability  heel_durability  \\\n",
       "0         5.74              3.74               2.92             2.98   \n",
       "1        12.03              3.41               3.26             3.32   \n",
       "2         4.52              0.89               0.00             0.00   \n",
       "3        11.11              1.80               0.33             0.47   \n",
       "\n",
       "   outsole_durability  ...  forefoot_lab_mm         terrain            arch  \\\n",
       "0                3.24  ...            25.97     light (69%)  neutral (100%)   \n",
       "1                3.68  ...            24.55     light (79%)   neutral (94%)   \n",
       "2                0.00  ...            24.52  moderate (78%)  neutral (100%)   \n",
       "3                0.27  ...            24.06     light (60%)   neutral (87%)   \n",
       "\n",
       "        strike  plate_rock_plate  plate_carbon_plate     season  \\\n",
       "0   mid (100%)          no (20%)             no (4%)  all (90%)   \n",
       "1  heel (100%)          no (18%)            no (12%)  all (79%)   \n",
       "2   mid (100%)          no (50%)             no (6%)  all (33%)   \n",
       "3   heel (93%)          no (13%)            no (13%)  all (53%)   \n",
       "\n",
       "  removable_insole waterproof water_repellent  \n",
       "0        yes (95%)    no (7%)         no (4%)  \n",
       "1       yes (100%)   no (18%)         no (3%)  \n",
       "2        yes (67%)    no (0%)         no (6%)  \n",
       "3       yes (100%)    no (7%)         no (0%)  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Masukkan Cluster ke DataFrame\n",
    "df['cluster'] = best_labels \n",
    "\n",
    "# Setup Grouping\n",
    "bin_groups = {}\n",
    "for col in binary_cols:\n",
    "    parts = col.split('_')\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        prefix = '_'.join(parts[:-1])\n",
    "    else:\n",
    "        prefix = col\n",
    "        \n",
    "    bin_groups.setdefault(prefix, []).append(col)\n",
    "\n",
    "# Build Summary Data\n",
    "rows = []\n",
    "for cid in sorted(df['cluster'].unique()):\n",
    "    subset = df[df['cluster'] == cid]\n",
    "    n = len(subset)\n",
    "    \n",
    "    row = {'count': n, 'percentage': f\"{n/len(df)*100:.1f}%\"}\n",
    "\n",
    "    # A. Continuous Columns: Langsung ambil mean\n",
    "    for col in continuous_cols:\n",
    "        row[col.lower()] = round(subset[col].mean(), 2)\n",
    "\n",
    "    # B. Binary Groups\n",
    "    for prefix, cols in bin_groups.items():\n",
    "        # Hitung mean grup ini\n",
    "        means = subset[cols].mean()\n",
    "        best_col = means.idxmax()\n",
    "        best_val = means.max()\n",
    "        \n",
    "        # Case 1: Multiple Variants\n",
    "        if len(cols) > 1:\n",
    "            header = prefix.lower()\n",
    "            val_str = best_col.replace(f\"{prefix}_\", \"\").lower()\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "            \n",
    "        # Case 2: Standalone\n",
    "        else:\n",
    "            header = cols[0].lower()\n",
    "            val_str = \"yes\" if best_val > 0.5 else \"no\"\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame & Fix Display\n",
    "df_summary = pd.DataFrame(rows, index=sorted(df['cluster'].unique()))\n",
    "df_summary.index.name = None \n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "display(df_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
