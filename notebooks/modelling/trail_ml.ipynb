{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cdf0b4",
   "metadata": {},
   "source": [
    "# Import Library & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "d37034b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n",
      "Time: 2026-02-11 10:58:38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISM'] = '1'\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "Deep Learning Framework\n",
    "TensorFlow & Keras: Autoencoder architecture with Dense, BatchNormalization, Dropout layers\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "Machine Learning & Metrics\n",
    "- KMeans: K-means clustering for shoe recommendation groups\n",
    "- StandardScaler/MinMaxScaler: Feature normalization for ML models\n",
    "- Clustering Metrics: Silhouette, Davies-Bouldin, Calinski-Harabasz indices\n",
    "- Similarity: Cosine similarity for recommendation ranking\n",
    "\"\"\"\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "Data Visualization\n",
    "Matplotlib & Seaborn for statistical plots and cluster visualization\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('Libraries loaded')\n",
    "print(f'Time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409bb62",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "93ac2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 158 shoes × 37 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>lightweight</th>\n",
       "      <th>terrain_light</th>\n",
       "      <th>terrain_moderate</th>\n",
       "      <th>terrain_technical</th>\n",
       "      <th>shock_absorption</th>\n",
       "      <th>energy_return</th>\n",
       "      <th>traction_scaled</th>\n",
       "      <th>arch_neutral</th>\n",
       "      <th>...</th>\n",
       "      <th>heel_stiff</th>\n",
       "      <th>lug_dept_mm</th>\n",
       "      <th>heel_lab_mm</th>\n",
       "      <th>forefoot_lab_mm</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>season_all</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex agravic speed ultra</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adidas</td>\n",
       "      <td>terrex speed ultra</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>34.5</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altra</td>\n",
       "      <td>experience wild 2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>altra</td>\n",
       "      <td>lone peak 5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                        name  lightweight  terrain_light  \\\n",
       "0  adidas  terrex agravic speed ultra            0              1   \n",
       "1  adidas          terrex speed ultra            0              1   \n",
       "2   altra             experience wild            0              1   \n",
       "3   altra           experience wild 2            0              1   \n",
       "4   altra               lone peak 5.0            0              1   \n",
       "\n",
       "   terrain_moderate  terrain_technical  shock_absorption  energy_return  \\\n",
       "0                 0                  0                 3              5   \n",
       "1                 0                  0                 0              0   \n",
       "2                 1                  0                 3              1   \n",
       "3                 0                  0                 3              1   \n",
       "4                 1                  0                 0              0   \n",
       "\n",
       "   traction_scaled  arch_neutral  ...  heel_stiff  lug_dept_mm  heel_lab_mm  \\\n",
       "0                0             1  ...           1          2.5         30.6   \n",
       "1                0             1  ...           1          2.6         32.8   \n",
       "2                0             1  ...           3          3.6         34.5   \n",
       "3                5             1  ...           1          3.5         32.3   \n",
       "4                0             1  ...           0          3.7         24.5   \n",
       "\n",
       "   forefoot_lab_mm  season_summer  season_winter  season_all  \\\n",
       "0             30.3              0              0           1   \n",
       "1             24.6              0              0           0   \n",
       "2             30.2              0              0           1   \n",
       "3             26.2              0              0           1   \n",
       "4             24.3              0              0           0   \n",
       "\n",
       "   removable_insole  waterproof  water_repellent  \n",
       "0                 1           0                0  \n",
       "1                 1           0                0  \n",
       "2                 1           0                0  \n",
       "3                 1           0                0  \n",
       "4                 1           0                0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = '../../data/trail_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Loaded: {df.shape[0]} shoes × {df.shape[1]} columns')\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"WARNING: '{file}' not found.\")\n",
    "    print(\"Please upload the correct dataset file to run with actual data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "5b87ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 37 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   brand                 158 non-null    str    \n",
      " 1   name                  158 non-null    str    \n",
      " 2   lightweight           158 non-null    int64  \n",
      " 3   terrain_light         158 non-null    int64  \n",
      " 4   terrain_moderate      158 non-null    int64  \n",
      " 5   terrain_technical     158 non-null    int64  \n",
      " 6   shock_absorption      158 non-null    int64  \n",
      " 7   energy_return         158 non-null    int64  \n",
      " 8   traction_scaled       158 non-null    int64  \n",
      " 9   arch_neutral          158 non-null    int64  \n",
      " 10  arch_stability        158 non-null    int64  \n",
      " 11  weight_lab_oz         158 non-null    float64\n",
      " 12  drop_lab_mm           158 non-null    float64\n",
      " 13  strike_heel           158 non-null    int64  \n",
      " 14  strike_mid            158 non-null    int64  \n",
      " 15  strike_forefoot       158 non-null    int64  \n",
      " 16  midsole_softness      158 non-null    int64  \n",
      " 17  toebox_durability     158 non-null    int64  \n",
      " 18  heel_durability       158 non-null    int64  \n",
      " 19  outsole_durability    158 non-null    int64  \n",
      " 20  breathability_scaled  158 non-null    int64  \n",
      " 21  plate_rock_plate      158 non-null    int64  \n",
      " 22  plate_carbon_plate    158 non-null    int64  \n",
      " 23  width_fit             158 non-null    int64  \n",
      " 24  toebox_width          158 non-null    int64  \n",
      " 25  stiffness_scaled      158 non-null    int64  \n",
      " 26  torsional_rigidity    158 non-null    int64  \n",
      " 27  heel_stiff            158 non-null    int64  \n",
      " 28  lug_dept_mm           158 non-null    float64\n",
      " 29  heel_lab_mm           158 non-null    float64\n",
      " 30  forefoot_lab_mm       158 non-null    float64\n",
      " 31  season_summer         158 non-null    int64  \n",
      " 32  season_winter         158 non-null    int64  \n",
      " 33  season_all            158 non-null    int64  \n",
      " 34  removable_insole      158 non-null    int64  \n",
      " 35  waterproof            158 non-null    int64  \n",
      " 36  water_repellent       158 non-null    int64  \n",
      "dtypes: float64(5), int64(30), str(2)\n",
      "memory usage: 45.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0f9b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b2d8c",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Separates numeric features into two categories for different preprocessing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "44420bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 35 total\n",
      "  Binary     : 17\n",
      "  Continuous : 18\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "binary_cols = [col for col in numeric_cols if set(df[col].unique()).issubset({0, 1})]\n",
    "continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "\n",
    "print(f'Features: {len(numeric_cols)} total')\n",
    "print(f'  Binary     : {len(binary_cols)}')\n",
    "print(f'  Continuous : {len(continuous_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "71d852a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 35 total\n",
      "  Binary     : 17\n",
      "  Continuous : 18\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "binary_cols = [col for col in numeric_cols if set(df[col].unique()).issubset({0, 1})]\n",
    "continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "\n",
    "print(f'Features: {len(numeric_cols)} total')\n",
    "print(f'  Binary     : {len(binary_cols)}')\n",
    "print(f'  Continuous : {len(continuous_cols)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890ac84",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "- Binary features: kept as-is (0-1 range)\n",
    "- Continuous features: MinMaxScaler to [0, 1]\n",
    "- Combined array: binary + continuous scaled features\n",
    "This ensures neural network compatibility and distance metric compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "074d2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural input shape: (158, 35)\n",
      "Range: [0.000000, 1.000000]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = numeric_cols.copy()\n",
    "X = df[feature_cols]\n",
    "\n",
    "X_binary = X[binary_cols].values\n",
    "X_continuous = X[continuous_cols].values\n",
    "\n",
    "scaler_continuous = MinMaxScaler()\n",
    "X_continuous_scaled = scaler_continuous.fit_transform(X_continuous)\n",
    "\n",
    "X_combined = np.concatenate([X_binary, X_continuous_scaled], axis=1)\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print(f'Neural input shape: {X_combined.shape}')\n",
    "print(f'Range: [{X_combined.min():.6f}, {X_combined.max():.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77513e",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b73e33",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "- Purpose: Dimensionality reduction (high-D features → 8D latent space)\n",
    "- Architecture: Encoder [input → 32 → 16 → 8] + Decoder [8 → 16 → 32 → reconstructed]\n",
    "- Regularization: BatchNormalization + Dropout(0.3) at each dense layer\n",
    "- Loss: MSE (reconstruction error) | Optimizer: Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "ce2eb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_82\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_82\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_280 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_239         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_239 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_281 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_240         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_240 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_282 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_241         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_241 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_283 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_242         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_242 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_284 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_243         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_243 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_285 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,155</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_41 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_280 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_239         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_239 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_281 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_240         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_240 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_282 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_241         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_241 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_283 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_242         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_242 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_284 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_243         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_243 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_285 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m1,155\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,075</span> (15.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,075\u001b[0m (15.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,867</span> (15.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,867\u001b[0m (15.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> (832.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m208\u001b[0m (832.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = X_combined.shape[1]\n",
    "encoding_dims = [32, 16, 8]\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = input_layer\n",
    "for dim in encoding_dims:\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "latent = x\n",
    "\n",
    "for dim in reversed(encoding_dims[:-1]):\n",
    "    x = Dense(dim, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "encoder = Model(input_layer, latent)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print('Autoencoder architecture:')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaab33",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training Configuration\n",
    "- Epochs: 300 (with early stopping)\n",
    "- Batch size: 64\n",
    "- Validation split: 20%\n",
    "- Early stopping: patience=20 (stop if val_loss doesn't improve)\n",
    "- LR reduction: factor=0.5, patience=10, min_lr=1e-5\n",
    "- Output: X_latent (8D embeddings) for KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "a6fb0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Final loss: 0.078108\n",
      "  Val loss: 0.078716\n",
      "Latent space: (158, 8) (8D embeddings)\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_combined, X_combined,\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    validation_split=0.25,\n",
    "    shuffle=False,\n",
    "    callbacks=[\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f'Training done!')\n",
    "print(f'Final loss: {history.history[\"loss\"][-1]:.6f}')\n",
    "print(f'  Val loss: {history.history[\"val_loss\"][-1]:.6f}')\n",
    "\n",
    "X_latent = encoder.predict(X_combined, verbose=0)\n",
    "print(f'Latent space: {X_latent.shape} (8D embeddings)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb6321",
   "metadata": {},
   "source": [
    "# Metrics Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789df65",
   "metadata": {},
   "source": [
    "## Interpretability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "601dd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_interpretability_score(df, cluster_col, binary_cols, top_n=5, threshold=0.70):\n",
    "    \"\"\"\n",
    "    Calculate cluster interpretability based on top feature clarity.\n",
    "    \n",
    "    Strategy: Focus on strongest features (not averages) to reduce noise.\n",
    "    Strength Definition: Distance from neutral point (0.5)\n",
    "      - Features closer to 0 or 1 = strong patterns\n",
    "      - Features closer to 0.5 = ambiguous patterns\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cluster-labeled dataset\n",
    "        cluster_col (str): Column with cluster assignments\n",
    "        binary_cols (list): Binary feature names\n",
    "        top_n (int): Number of top features to evaluate (default: 5)\n",
    "        threshold (float): Unused parameter (API compatibility)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'mean_interpretability': float [0, 1]}\n",
    "              1.0 = clear feature patterns, 0.0 = no patterns\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "    \n",
    "    for cid in unique_clusters:\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        if n == 0: \n",
    "            scores.append(0)\n",
    "            continue\n",
    "        \n",
    "        feature_strength = []\n",
    "        for col in binary_cols:\n",
    "            if col in cdata.columns:\n",
    "                avg = cdata[col].mean()\n",
    "                strength = abs(avg - 0.5) * 2  # Normalize distance from neutral (0.5) to [0, 1]\n",
    "                feature_strength.append(strength)\n",
    "        \n",
    "        if feature_strength:\n",
    "            feature_strength.sort(reverse=True)\n",
    "            top_features = feature_strength[:top_n]\n",
    "            scores.append(np.mean(top_features))  # Average of top-N features\n",
    "        else:\n",
    "            scores.append(0)\n",
    "            \n",
    "    return {'mean_interpretability': np.mean(scores) if scores else 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4699d",
   "metadata": {},
   "source": [
    "## Cluster Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "41ebefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cluster_purity(df, cluster_col, binary_cols):\n",
    "    \"\"\"\n",
    "    Measure internal cluster homogeneity via majority class dominance.\n",
    "    \n",
    "    Purity Calculation: For each feature, compute max(class0_pct, class1_pct)\n",
    "    Average across all features = cluster purity\n",
    "    Range: [0.5, 1.0] where 1.0 = perfect homogeneity\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cluster-labeled dataset\n",
    "        cluster_col (str): Column with cluster assignments\n",
    "        binary_cols (list): Binary feature names\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'mean_purity': float [0.5, 1.0]}\n",
    "    \"\"\"\n",
    "    purity_by_cluster = []\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "    \n",
    "    for cid in unique_clusters:\n",
    "        cdata = df[df[cluster_col] == cid]\n",
    "        n = len(cdata)\n",
    "        if n == 0: continue\n",
    "        \n",
    "        dominances = []\n",
    "        for col in binary_cols:\n",
    "            if col in cdata.columns:\n",
    "                avg = cdata[col].mean()\n",
    "                dominances.append(max(avg, 1 - avg))  # Majority class percentage\n",
    "        \n",
    "        if dominances:\n",
    "            purity_by_cluster.append(np.mean(dominances))\n",
    "    \n",
    "    return {'mean_purity': np.mean(purity_by_cluster) if purity_by_cluster else 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373c67f",
   "metadata": {},
   "source": [
    "## Cluster Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "059bd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cluster_stability(X, labels, model_func, n_iter=5, seed=42):\n",
    "    \"\"\"\n",
    "    Bootstrap stability testing via Adjusted Rand Index (ARI).\n",
    "    \n",
    "    Process:\n",
    "    1. Train model on bootstrap sample (with replacement)\n",
    "    2. Compare original vs bootstrap clustering using ARI\n",
    "    3. Average ARI across iterations\n",
    "    \n",
    "    ARI Range: [-1, 1]\n",
    "      > 0.5: excellent stability\n",
    "      0.2-0.5: fair stability\n",
    "      < 0.2: poor stability\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix\n",
    "        labels (np.ndarray): Original cluster assignments\n",
    "        model_func (callable): Returns instantiated clustering model\n",
    "        n_iter (int): Bootstrap iterations (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'mean_ari': float [-1, 1]}\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        return {'mean_ari': 0}\n",
    "\n",
    "    n = len(X)\n",
    "    ari_scores = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        rng = np.random.default_rng(seed=42 + i)\n",
    "        idx = rng.choice(n, n, replace=True)\n",
    "        try:\n",
    "            boot_model = model_func()\n",
    "            boot_labels = boot_model.fit_predict(X[idx])\n",
    "            ari = adjusted_rand_score(labels[idx], boot_labels)\n",
    "            ari_scores.append(ari)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    m = np.mean(ari_scores) if ari_scores else 0\n",
    "    return {'mean_ari': m}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b1f8d",
   "metadata": {},
   "source": [
    "## Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "acbf4808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Metrics Function Ready.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_clustering_comprehensive(X, labels, df_original, model_func, binary_cols):\n",
    "    \"\"\"\n",
    "    Multi-metric clustering evaluation combining geometric and business metrics.\n",
    "    \n",
    "    Evaluation Framework:\n",
    "    \n",
    "    1. GEOMETRIC METRICS (Scikit-learn):\n",
    "       Silhouette [-1, 1]: cluster separation quality\n",
    "       Davies-Bouldin [0, ∞): intra-cluster density (lower better)\n",
    "       Calinski-Harabasz [0, ∞): cluster definition (higher better)\n",
    "    \n",
    "    2. BUSINESS METRICS:\n",
    "       Purity: internal homogeneity\n",
    "       Interpretability: feature pattern clarity\n",
    "       Stability: clustering consistency\n",
    "    \n",
    "    3. COMPOSITE SCORING (strategic weights):\n",
    "       Structure (40%): 40% Silhouette + 30% Davies-Bouldin + 40% Calinski-Harabasz\n",
    "       Explainability (30%): 50% Interpretability + 50% Purity\n",
    "       Reliability (30%): Bootstrap ARI stability\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Latent feature space (typically autoencoder output)\n",
    "        labels (np.ndarray): Cluster assignments [0, K-1]\n",
    "        df_original (pd.DataFrame): Original shoe metadata\n",
    "        model_func (callable): KMeans factory function\n",
    "        binary_cols (list): Binary feature column names\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'metrics': {silhouette, davies_bouldin, calinski_harabasz, purity, stability, interpretability},\n",
    "            'composite_score': float [0, 1]\n",
    "        }\n",
    "    \"\"\"\n",
    "    df_eval = df_original.copy()\n",
    "    df_eval['cluster'] = labels\n",
    "    \n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    \n",
    "    purity_res = calculate_cluster_purity(df_eval, 'cluster', binary_cols)\n",
    "    interp_res = calculate_interpretability_score(df_eval, 'cluster', binary_cols, top_n=5)\n",
    "    stability_res = calculate_cluster_stability(X, labels, model_func, n_iter=3)\n",
    "    \n",
    "    val_purity = purity_res['mean_purity']\n",
    "    val_interp = interp_res['mean_interpretability']\n",
    "    val_stability = stability_res['mean_ari']\n",
    "\n",
    "    sil_norm = (sil + 1) / 2  # Map Silhouette [-1, 1] → [0, 1]\n",
    "    db_norm = np.exp(-0.5 * db)  # Exponential decay: DB lower is better\n",
    "    \n",
    "    if ch > 0:\n",
    "        ch_log = np.log1p(ch)\n",
    "        ch_norm = min(ch_log / 8, 1.0)  # Log scaling: assume max log(CH) ≈ 9.2\n",
    "    else:\n",
    "        ch_norm = 0\n",
    "\n",
    "    score_structure = (0.4 * sil_norm) + (0.3 * db_norm) + (0.3 * ch_norm)  # Weight: Silhouette 40%, DB 30%, CH 30%\n",
    "    score_explain = (0.5 * val_interp) + (0.5 * val_purity)  # Weight: Interpretability 50%, Purity 50%\n",
    "    score_reliability = max(val_stability, 0)  # Clip negative ARI to 0\n",
    "\n",
    "    composite = (0.40 * score_structure) + (0.30 * score_explain) + (0.30 * score_reliability)\n",
    " \n",
    "    return {\n",
    "        'metrics': {\n",
    "            'silhouette': sil, \n",
    "            'davies_bouldin': db, \n",
    "            'calinski_harabasz': ch,\n",
    "            'purity': val_purity, \n",
    "            'stability': val_stability,\n",
    "            'interpretability': val_interp\n",
    "        },\n",
    "        'composite_score': composite\n",
    "    }\n",
    "\n",
    "print('Optimized Metrics Function Ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ba812",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "Model Selection Pipeline: K-means Clustering (K=3 to K=9)\n",
    "\n",
    "For each K value:\n",
    "  - Train KMeans model\n",
    "  - Evaluate using comprehensive metrics\n",
    "  - Compute composite score\n",
    "\n",
    "Select K with highest composite score (40% geometry, 30% explainability, 30% reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "8e1f4985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  K  |  Score   |   Sil.   |    DB    |     CH     |  Purity  |  Stab.   |  Interp  |\n",
      "|-----+----------+----------+----------+------------+----------+----------+----------|\n",
      "|  3  | 0.765033 | 0.375950 | 1.123361 | 72.019419 | 0.857093 | 0.827530 | 0.968952 |\n",
      "|  4  | 0.823837 | 0.434731 | 0.908956 | 92.039301 | 0.879525 | 0.953780 | 0.978846 |\n",
      "|  5  | 0.846234 | 0.466877 | 0.762381 | 119.549157 | 0.881545 | 0.983211 | 0.985616 |\n",
      "|  6  | 0.785558 | 0.469993 | 0.784870 | 108.848327 | 0.888658 | 0.778595 | 0.996970 |\n",
      "|  7  | 0.751643 | 0.431342 | 0.899164 | 102.980001 | 0.889365 | 0.692877 | 0.997714 |\n",
      "|  8  | 0.783562 | 0.382712 | 0.941965 | 99.927615 | 0.887725 | 0.818811 | 1.000000 |\n",
      "|  9  | 0.801397 | 0.380008 | 0.995231 | 98.352993 | 0.898996 | 0.880696 | 1.000000 |\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "print(f\"| {'K':^3} | {'Score':^8} | {'Sil.':^8} | {'DB':^8} | {'CH':^10} | {'Purity':^8} | {'Stab.':^8} | {'Interp':^8} |\")\n",
    "print(f\"|{'-'*5}+{'-'*10}+{'-'*10}+{'-'*10}+{'-'*12}+{'-'*10}+{'-'*10}+{'-'*10}|\")\n",
    "\n",
    "for i in range(3, 10):\n",
    "    model_factory = lambda: KMeans(n_clusters=i, random_state=42, n_init=20)\n",
    "    \n",
    "    model = model_factory()\n",
    "    labels = model.fit_predict(X_latent)\n",
    "\n",
    "    metrics_res = evaluate_clustering_comprehensive(\n",
    "        X_latent, labels, df.copy(),\n",
    "        model_factory,\n",
    "        binary_cols\n",
    "    )\n",
    "\n",
    "    raw_metrics = metrics_res['metrics'] \n",
    "    comp_score  = metrics_res['composite_score']\n",
    "\n",
    "    record = {\n",
    "        'k': i,\n",
    "        'model': model,\n",
    "        'labels': labels,\n",
    "        'composite_score': comp_score,\n",
    "        **raw_metrics\n",
    "    }\n",
    "    results.append(record)\n",
    "\n",
    "    print(f\"| {i:^3} | {comp_score:<8.6f} | {raw_metrics['silhouette']:<6.6f} | \"\n",
    "          f\"{raw_metrics['davies_bouldin']:<6.6f} | {raw_metrics['calinski_harabasz']:<8.6f} | \"\n",
    "          f\"{raw_metrics['purity']:<6.6f} | {raw_metrics['stability']:<6.6f} | {raw_metrics['interpretability']:<6.6f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "3aa23de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SELECTED BEST K: 5\n",
      "   Silhouette      : 0.466877\n",
      "   Composite Score : 0.846234\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "best_idx = df_results['composite_score'].idxmax()\n",
    "best_config = df_results.loc[best_idx]\n",
    "\n",
    "best_model = best_config['model']\n",
    "best_labels = best_config['labels']\n",
    "best_k = best_config['k']\n",
    "X_for_clustering = X_latent\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f'SELECTED BEST K: {best_k}')\n",
    "print(f'   Silhouette      : {best_config[\"silhouette\"]:.6f}') \n",
    "print(f'   Composite Score : {best_config[\"composite_score\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84409589",
   "metadata": {},
   "source": [
    "# Generate Cluster Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedd13e",
   "metadata": {},
   "source": [
    "## Binning\n",
    "Divides each continuous feature into 3 quantile bins (tertiles).\n",
    "\n",
    "Labels: 0 (low), 0.5 (medium), 1 (high)\n",
    "\n",
    "Enables interpretable cluster profiling and feature discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "ecb087b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('float64').columns.tolist():\n",
    "    new_col_name = col + '_bin'\n",
    "    df[new_col_name] = pd.qcut(df[col], q=3, labels=[0, 0.5, 1]).astype(int)\n",
    "\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "new_column_order = []\n",
    "\n",
    "for col in non_numeric_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        new_column_order.append(col)\n",
    "    bin_col_name = col + '_bin'\n",
    "    if bin_col_name in df.columns:\n",
    "        new_column_order.append(bin_col_name)\n",
    "\n",
    "if 'cluster' in df.columns and 'cluster' not in new_column_order:\n",
    "    new_column_order.append('cluster')\n",
    "\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "9e638024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 42 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   brand                 158 non-null    str    \n",
      " 1   name                  158 non-null    str    \n",
      " 2   lightweight           158 non-null    int64  \n",
      " 3   terrain_light         158 non-null    int64  \n",
      " 4   terrain_moderate      158 non-null    int64  \n",
      " 5   terrain_technical     158 non-null    int64  \n",
      " 6   arch_neutral          158 non-null    int64  \n",
      " 7   arch_stability        158 non-null    int64  \n",
      " 8   strike_heel           158 non-null    int64  \n",
      " 9   strike_mid            158 non-null    int64  \n",
      " 10  strike_forefoot       158 non-null    int64  \n",
      " 11  plate_rock_plate      158 non-null    int64  \n",
      " 12  plate_carbon_plate    158 non-null    int64  \n",
      " 13  season_summer         158 non-null    int64  \n",
      " 14  season_winter         158 non-null    int64  \n",
      " 15  season_all            158 non-null    int64  \n",
      " 16  removable_insole      158 non-null    int64  \n",
      " 17  waterproof            158 non-null    int64  \n",
      " 18  water_repellent       158 non-null    int64  \n",
      " 19  shock_absorption      158 non-null    int64  \n",
      " 20  energy_return         158 non-null    int64  \n",
      " 21  traction_scaled       158 non-null    int64  \n",
      " 22  weight_lab_oz         158 non-null    float64\n",
      " 23  weight_lab_oz_bin     158 non-null    int64  \n",
      " 24  drop_lab_mm           158 non-null    float64\n",
      " 25  drop_lab_mm_bin       158 non-null    int64  \n",
      " 26  midsole_softness      158 non-null    int64  \n",
      " 27  toebox_durability     158 non-null    int64  \n",
      " 28  heel_durability       158 non-null    int64  \n",
      " 29  outsole_durability    158 non-null    int64  \n",
      " 30  breathability_scaled  158 non-null    int64  \n",
      " 31  width_fit             158 non-null    int64  \n",
      " 32  toebox_width          158 non-null    int64  \n",
      " 33  stiffness_scaled      158 non-null    int64  \n",
      " 34  torsional_rigidity    158 non-null    int64  \n",
      " 35  heel_stiff            158 non-null    int64  \n",
      " 36  lug_dept_mm           158 non-null    float64\n",
      " 37  lug_dept_mm_bin       158 non-null    int64  \n",
      " 38  heel_lab_mm           158 non-null    float64\n",
      " 39  heel_lab_mm_bin       158 non-null    int64  \n",
      " 40  forefoot_lab_mm       158 non-null    float64\n",
      " 41  forefoot_lab_mm_bin   158 non-null    int64  \n",
      "dtypes: float64(5), int64(35), str(2)\n",
      "memory usage: 52.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb72334",
   "metadata": {},
   "source": [
    "## Cluster Summary\n",
    "Creates interpretable profile for each cluster showing:\n",
    "- Size (count + percentage)\n",
    "- Continuous features (mean values)\n",
    "- Binary features (dominant variant + prevalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "c58df965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>shock_absorption</th>\n",
       "      <th>energy_return</th>\n",
       "      <th>traction_scaled</th>\n",
       "      <th>weight_lab_oz</th>\n",
       "      <th>drop_lab_mm</th>\n",
       "      <th>midsole_softness</th>\n",
       "      <th>toebox_durability</th>\n",
       "      <th>heel_durability</th>\n",
       "      <th>...</th>\n",
       "      <th>lightweight</th>\n",
       "      <th>terrain</th>\n",
       "      <th>arch</th>\n",
       "      <th>strike</th>\n",
       "      <th>plate_rock_plate</th>\n",
       "      <th>plate_carbon_plate</th>\n",
       "      <th>season</th>\n",
       "      <th>removable_insole</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>water_repellent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>28.5%</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10.27</td>\n",
       "      <td>10.88</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.29</td>\n",
       "      <td>...</td>\n",
       "      <td>no (4%)</td>\n",
       "      <td>light (87%)</td>\n",
       "      <td>neutral (96%)</td>\n",
       "      <td>heel (93%)</td>\n",
       "      <td>no (7%)</td>\n",
       "      <td>no (16%)</td>\n",
       "      <td>all (93%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (2%)</td>\n",
       "      <td>no (0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>38.0%</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.21</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>no (12%)</td>\n",
       "      <td>light (93%)</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (100%)</td>\n",
       "      <td>no (20%)</td>\n",
       "      <td>no (3%)</td>\n",
       "      <td>all (95%)</td>\n",
       "      <td>yes (92%)</td>\n",
       "      <td>no (5%)</td>\n",
       "      <td>no (5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>no (9%)</td>\n",
       "      <td>moderate (73%)</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (82%)</td>\n",
       "      <td>no (45%)</td>\n",
       "      <td>no (5%)</td>\n",
       "      <td>all (23%)</td>\n",
       "      <td>yes (73%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7.0%</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.90</td>\n",
       "      <td>11.18</td>\n",
       "      <td>2.64</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.09</td>\n",
       "      <td>...</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>moderate (73%)</td>\n",
       "      <td>neutral (82%)</td>\n",
       "      <td>heel (82%)</td>\n",
       "      <td>no (27%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>winter (91%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>yes (82%)</td>\n",
       "      <td>no (9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.28</td>\n",
       "      <td>6.37</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>moderate (85%)</td>\n",
       "      <td>neutral (100%)</td>\n",
       "      <td>mid (100%)</td>\n",
       "      <td>no (35%)</td>\n",
       "      <td>no (5%)</td>\n",
       "      <td>all (90%)</td>\n",
       "      <td>yes (100%)</td>\n",
       "      <td>no (0%)</td>\n",
       "      <td>no (5%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count percentage  shock_absorption  energy_return  traction_scaled  \\\n",
       "0     45      28.5%              1.84           1.04             0.84   \n",
       "1     60      38.0%              2.02           1.45             1.33   \n",
       "2     22      13.9%              0.00           0.00             0.00   \n",
       "3     11       7.0%              0.45           0.27             0.00   \n",
       "4     20      12.7%              1.90           1.60             0.50   \n",
       "\n",
       "   weight_lab_oz  drop_lab_mm  midsole_softness  toebox_durability  \\\n",
       "0          10.27        10.88              3.40               2.07   \n",
       "1          10.00         5.21              3.67               2.97   \n",
       "2          10.13         5.75              0.59               0.00   \n",
       "3          10.90        11.18              2.64               4.09   \n",
       "4          10.28         6.37              4.20               3.30   \n",
       "\n",
       "   heel_durability  ...  lightweight         terrain            arch  \\\n",
       "0             2.29  ...      no (4%)     light (87%)   neutral (96%)   \n",
       "1             3.07  ...     no (12%)     light (93%)  neutral (100%)   \n",
       "2             0.00  ...      no (9%)  moderate (73%)  neutral (100%)   \n",
       "3             3.09  ...      no (0%)  moderate (73%)   neutral (82%)   \n",
       "4             3.50  ...      no (0%)  moderate (85%)  neutral (100%)   \n",
       "\n",
       "       strike  plate_rock_plate  plate_carbon_plate        season  \\\n",
       "0  heel (93%)           no (7%)            no (16%)     all (93%)   \n",
       "1  mid (100%)          no (20%)             no (3%)     all (95%)   \n",
       "2   mid (82%)          no (45%)             no (5%)     all (23%)   \n",
       "3  heel (82%)          no (27%)             no (0%)  winter (91%)   \n",
       "4  mid (100%)          no (35%)             no (5%)     all (90%)   \n",
       "\n",
       "   removable_insole  waterproof  water_repellent  \n",
       "0        yes (100%)     no (2%)          no (0%)  \n",
       "1         yes (92%)     no (5%)          no (5%)  \n",
       "2         yes (73%)     no (0%)          no (5%)  \n",
       "3        yes (100%)   yes (82%)          no (9%)  \n",
       "4        yes (100%)     no (0%)          no (5%)  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['cluster'] = best_labels \n",
    "\n",
    "bin_groups = {}\n",
    "for col in binary_cols:\n",
    "    parts = col.split('_')\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        prefix = '_'.join(parts[:-1])\n",
    "    else:\n",
    "        prefix = col\n",
    "        \n",
    "    bin_groups.setdefault(prefix, []).append(col)\n",
    "\n",
    "rows = []\n",
    "for cid in sorted(df['cluster'].unique()):\n",
    "    subset = df[df['cluster'] == cid]\n",
    "    n = len(subset)\n",
    "    \n",
    "    row = {'count': n, 'percentage': f\"{n/len(df)*100:.1f}%\"}\n",
    "\n",
    "    for col in continuous_cols:\n",
    "        row[col.lower()] = round(subset[col].mean(), 2)\n",
    "\n",
    "    for prefix, cols in bin_groups.items():\n",
    "        means = subset[cols].mean()\n",
    "        best_col = means.idxmax()\n",
    "        best_val = means.max()\n",
    "        \n",
    "        if len(cols) > 1:\n",
    "            header = prefix.lower()\n",
    "            val_str = best_col.replace(f\"{prefix}_\", \"\").lower()\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "            \n",
    "        else:\n",
    "            header = cols[0].lower()\n",
    "            val_str = \"yes\" if best_val > 0.5 else \"no\"\n",
    "            row[header] = f\"{val_str} ({best_val*100:.0f}%)\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(rows, index=sorted(df['cluster'].unique()))\n",
    "df_summary.index.name = None \n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa3aff",
   "metadata": {},
   "source": [
    "# Deep Learn Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b760e",
   "metadata": {},
   "source": [
    "## Priority Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "9225b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priority_val(user_input, priority_list, mapping_dicts):\n",
    "    \"\"\"\n",
    "    Extract feature value from user input with priority hierarchy.\n",
    "    \n",
    "    Strategy: Checks inputs in priority order, returns mapped value from\n",
    "    first non-empty input, ignores lower-priority inputs if higher-priority exists.\n",
    "    \n",
    "    Args:\n",
    "        user_input (dict): User preferences {'running_purpose': 'Daily', ...}\n",
    "        priority_list (list): Input sources in priority order\n",
    "        mapping_dicts (dict): Maps {source: {option: feature_value}}\n",
    "    \n",
    "    Returns:\n",
    "        float: Feature value [0, 1] or 0.5 (neutral) if not found\n",
    "    \"\"\"\n",
    "    for source_key in priority_list:\n",
    "        if source_key in user_input and user_input[source_key]:\n",
    "            user_choice = user_input[source_key]\n",
    "            if source_key in mapping_dicts:\n",
    "                mapping = mapping_dicts[source_key]\n",
    "                if user_choice in mapping:\n",
    "                    return mapping[user_choice]\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb5f6",
   "metadata": {},
   "source": [
    "## Input Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "id": "a44b15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_user_input_with_mask(user_input, binary_cols, continuous_cols):\n",
    "    \"\"\"\n",
    "    Translates user inputs (Terrain, Pace, etc.) into 34 engineered features \n",
    "    based on the specific logic provided.\n",
    "    \"\"\"\n",
    "    feats = {col: 0.0 for col in binary_cols + continuous_cols}\n",
    "    \n",
    "    feats['terrain_light']     = get_priority_val(user_input, ['terrain'], {'terrain': {'Light': 1.0, 'Mixed': 0.5, 'Rocky': 0.0, 'Muddy': 0.0}})\n",
    "    feats['terrain_moderate']  = get_priority_val(user_input, ['terrain'], {'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 0.5, 'Muddy': 0.5}})\n",
    "    feats['terrain_technical'] = get_priority_val(user_input, ['terrain'], {'terrain': {'Light': 0.0, 'Mixed': 0.5, 'Rocky': 1.0, 'Muddy': 1.0}})\n",
    "\n",
    "    feats['shock_absorption']  = get_priority_val(user_input, ['rock_sensitive', 'terrain'], \n",
    "                                                  {'rock_sensitive': {'Yes': 1.0, 'No': 0.0}, \n",
    "                                                   'terrain': {'Light': 0.2, 'Mixed': 0.6, 'Rocky': 1.0, 'Muddy': 0.0}})\n",
    "\n",
    "    feats['energy_return'] = 1.0\n",
    "\n",
    "    feats['traction_scaled'] = get_priority_val(user_input, ['terrain'], {'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 0.5, 'Muddy': 1.0}})\n",
    "\n",
    "    feats['arch_neutral']   = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 0.0, 'Neutral': 0.8, 'High': 1.0}})\n",
    "    feats['arch_stability'] = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 1.0, 'Neutral': 0.2, 'High': 0.0}})\n",
    "\n",
    "    feats['drop_lab_mm'] = get_priority_val(user_input, ['pace'], {'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}})\n",
    "\n",
    "    prio_strike = ['strike_pattern', 'pace']\n",
    "    feats['strike_heel']     = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 1.0, 'Mid': 0.5, 'Forefoot': 0.0}, 'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}})\n",
    "    feats['strike_mid']      = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 0.5, 'Mid': 1.0, 'Forefoot': 0.5}, 'pace': {'Easy': 0.5, 'Steady': 1.0, 'Fast': 0.5}})\n",
    "    feats['strike_forefoot'] = get_priority_val(user_input, prio_strike, {'strike_pattern': {'Heel': 0.0, 'Mid': 0.0, 'Forefoot': 1.0}, 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}})\n",
    "\n",
    "    feats['midsole_softness'] = get_priority_val(user_input, ['pace'], {'pace': {'Easy': 1.0, 'Steady': 0.6, 'Fast': 0.2}})\n",
    "\n",
    "    feats['toebox_durability']  = 1.0\n",
    "    feats['heel_durability']    = 1.0\n",
    "    feats['outsole_durability'] = 1.0\n",
    "    feats['breathability']      = 1.0\n",
    "\n",
    "    feats['plate_rock_plate'] = get_priority_val(user_input, ['pace', 'terrain'], \n",
    "                                                 {'pace': {'Easy': 0.5, 'Steady': 0.5, 'Fast': 0.5}, \n",
    "                                                  'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 1.0, 'Muddy': 1.0}})\n",
    "\n",
    "    feats['plate_carbon_plate'] = get_priority_val(user_input, ['pace', 'terrain'], \n",
    "                                                   {'pace': {'Easy': 0.5, 'Steady': 0.5, 'Fast': 1.0}, \n",
    "                                                    'terrain': {'Light': 0.5, 'Mixed': 0.5, 'Rocky': 0.5, 'Muddy': 0.5}})\n",
    "\n",
    "    feats['width_fit']    = get_priority_val(user_input, ['foot_width'], {'foot_width': {'Narrow': 0.2, 'Medium': 0.6, 'Wide': 1.0}})\n",
    "    feats['toebox_width'] = get_priority_val(user_input, ['foot_width'], {'foot_width': {'Narrow': 0.2, 'Medium': 0.6, 'Wide': 1.0}})\n",
    "\n",
    "    feats['stiffness_scaled'] = get_priority_val(user_input, ['pace'], {'pace': {'Easy': 0.2, 'Steady': 0.6, 'Fast': 1.0}})\n",
    "\n",
    "    feats['torsional_rigidity'] = get_priority_val(user_input, ['arch_type', 'pace'], \n",
    "                                                   {'arch_type': {'Low': 1.0, 'Neutral': 0.5, 'High': 0.5}, \n",
    "                                                    'pace': {'Easy': 0.2, 'Steady': 0.6, 'Fast': 1.0}})\n",
    "\n",
    "    feats['heel_stiff'] = get_priority_val(user_input, ['arch_type'], {'arch_type': {'Low': 1.0, 'Neutral': 0.6, 'High': 0.2}})\n",
    "\n",
    "    feats['lug_depth'] = get_priority_val(user_input, ['terrain'], {'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 0.5, 'Muddy': 1.0}})\n",
    "\n",
    "    prio_stack_h = ['strike_pattern', 'pace', 'terrain']\n",
    "    feats['heel_lab_mm'] = get_priority_val(user_input, prio_stack_h, \n",
    "                                            {'strike_pattern': {'Heel': 1.0, 'Mid': 0.5, 'Forefoot': 0.0}, \n",
    "                                             'pace': {'Easy': 1.0, 'Steady': 0.5, 'Fast': 0.0}, \n",
    "                                             'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 1.0, 'Muddy': 1.0}})\n",
    "\n",
    "    prio_stack_f = ['strike_pattern', 'pace', 'terrain']\n",
    "    feats['forefoot_lab_mm'] = get_priority_val(user_input, prio_stack_f, \n",
    "                                                {'strike_pattern': {'Heel': 0.0, 'Mid': 0.5, 'Forefoot': 1.0}, \n",
    "                                                 'pace': {'Easy': 0.0, 'Steady': 0.5, 'Fast': 1.0}, \n",
    "                                                 'terrain': {'Light': 0.5, 'Mixed': 0.5, 'Rocky': 0.5, 'Muddy': 0.5}})\n",
    "\n",
    "    feats['season_summer'] = get_priority_val(user_input, ['season'], {'season': {'Summer': 1.0, 'Spring, Fall': 0.5, 'Winter': 0.0}})\n",
    "    feats['season_winter'] = get_priority_val(user_input, ['season'], {'season': {'Summer': 0.0, 'Spring, Fall': 0.0, 'Winter': 1.0}})\n",
    "    feats['season_all']    = get_priority_val(user_input, ['season'], {'season': {'Summer': 0.5, 'Spring, Fall': 1.0, 'Winter': 0.0}})\n",
    "\n",
    "    feats['removable_insole'] = get_priority_val(user_input, ['orthotic_usage'], {'orthotic_usage': {'Yes': 1.0, 'No': 0.5}})\n",
    "\n",
    "    feats['waterproof'] = get_priority_val(user_input, ['water_resistance', 'terrain'], \n",
    "                                           {'water_resistance': {'Waterproof': 1.0, 'Water Repellent': 0.5}, \n",
    "                                            'terrain': {'Light': 0.5, 'Mixed': 0.5, 'Rocky': 0.5, 'Muddy': 1.0}})\n",
    "\n",
    "    feats['water_repellent'] = get_priority_val(user_input, ['water_resistance', 'terrain'], \n",
    "                                                {'water_resistance': {'Waterproof': 1.0, 'Water Repellent': 1.0}, \n",
    "                                                 'terrain': {'Light': 0.5, 'Mixed': 1.0, 'Rocky': 0.5, 'Muddy': 1.0}})\n",
    "\n",
    "    feats['lightweight'] = get_priority_val(user_input, ['pace'], {'pace': {'Easy': 0.5, 'Steady': 0.5, 'Fast': 1.0}})\n",
    "\n",
    "\n",
    "    provided_inputs = {k for k, v in user_input.items() if v}  # Track which inputs user provided\n",
    "\n",
    "    feature_sources = {\n",
    "        'terrain_light': ['terrain'], \n",
    "        'terrain_moderate': ['terrain'], \n",
    "        'terrain_technical': ['terrain'],\n",
    "        'shock_absorption': ['rock_sensitive', 'terrain'],\n",
    "        'traction_scaled': ['terrain'],\n",
    "        'arch_neutral': ['arch_type'], \n",
    "        'arch_stability': ['arch_type'],\n",
    "        'drop_lab_mm': ['pace'],\n",
    "        'strike_heel': ['strike_pattern', 'pace'], \n",
    "        'strike_mid': ['strike_pattern', 'pace'], \n",
    "        'strike_forefoot': ['strike_pattern', 'pace'],\n",
    "        'midsole_softness': ['pace'],\n",
    "        'plate_rock_plate': ['pace', 'terrain'],\n",
    "        'plate_carbon_plate': ['pace', 'terrain'],\n",
    "        'width_fit': ['foot_width'], \n",
    "        'toebox_width': ['foot_width'],\n",
    "        'stiffness_scaled': ['pace'],\n",
    "        'torsional_rigidity': ['arch_type', 'pace'],\n",
    "        'heel_stiff': ['arch_type'],\n",
    "        'lug_depth': ['terrain'],\n",
    "        'heel_lab_mm': ['strike_pattern', 'pace', 'terrain'],\n",
    "        'forefoot_lab_mm': ['strike_pattern', 'pace', 'terrain'],\n",
    "        'season_summer': ['season'], \n",
    "        'season_winter': ['season'], \n",
    "        'season_all': ['season'],\n",
    "        'removable_insole': ['orthotic_usage'],\n",
    "        'waterproof': ['water_resistance', 'terrain'],\n",
    "        'water_repellent': ['water_resistance', 'terrain'],\n",
    "        'lightweight': ['pace'],\n",
    "        'energy_return': [], 'toebox_durability': [], 'heel_durability': [], 'outsole_durability': [], 'breathability': []\n",
    "    }\n",
    "\n",
    "    all_cols = binary_cols + continuous_cols\n",
    "    full_vector_raw = []\n",
    "    for col in binary_cols:\n",
    "        full_vector_raw.append(feats.get(col, 0.0))\n",
    "    for col in continuous_cols:\n",
    "        full_vector_raw.append(feats.get(col, 0.5))\n",
    "\n",
    "    valid_indices = []\n",
    "    for i, col in enumerate(all_cols):\n",
    "        sources = feature_sources.get(col, [])\n",
    "        # Fitur dianggap valid jika SALAH SATU source input-nya ada\n",
    "        if any(src in provided_inputs for src in sources):\n",
    "            valid_indices.append(i)\n",
    "            \n",
    "    if not valid_indices:\n",
    "        valid_indices = list(range(len(all_cols)))\n",
    "        \n",
    "    return full_vector_raw, valid_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ec844",
   "metadata": {},
   "source": [
    "## Reccomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "8f25c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_shoes_deep_masked(user_input, df_data, encoder_model, kmeans_model, binary_cols, continuous_cols, X_combined_data):\n",
    "    \"\"\"\n",
    "    Deep Learning Recommendation Pipeline with Masked Similarity.\n",
    "    \n",
    "    Pipeline:\n",
    "    1. USER PREPROCESSING: Convert user preferences to feature vector with masking\n",
    "    2. CLUSTER ROUTING: Encode user→latent space, select top K/3 closest clusters\n",
    "    3. CANDIDATE RANKING: Score shoes via masked cosine similarity\n",
    "    4. RESULT: Return top 10 ranked recommendations\n",
    "    \n",
    "    Masking Benefits:\n",
    "    - Reduces noise from unanswered questions\n",
    "    - Focuses similarity on user-provided dimensions only\n",
    "    - Example: if user only provided 'pace', similarity computed on pace-related features\n",
    "    \n",
    "    Args:\n",
    "        user_input (dict): User questionnaire responses\n",
    "        df_data (pd.DataFrame): Shoe catalog\n",
    "        encoder_model: Trained keras encoder\n",
    "        kmeans_model: Trained KMeans model (K clusters)\n",
    "        binary_cols (list): Binary feature names\n",
    "        continuous_cols (list): Continuous feature names\n",
    "        X_combined_data (np.ndarray): Preprocessed feature matrix (n_shoes, n_features)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Top 10 shoes with index (row number) and match_score, sorted descending\n",
    "    \"\"\"\n",
    "    full_vector, valid_idx = preprocess_user_input_with_mask(user_input, binary_cols, continuous_cols)\n",
    "    full_vector = np.array([full_vector])\n",
    "\n",
    "    user_latent = encoder_model.predict(full_vector, verbose=0)\n",
    "    distances = kmeans_model.transform(user_latent)[0]\n",
    "    n_select = math.ceil(kmeans_model.n_clusters / 3)  # Select top 1/3 clusters for diversity\n",
    "    closest_clusters = np.argsort(distances)[:n_select]\n",
    "    \n",
    "    print(f\"User mapped to Clusters: {closest_clusters}\")\n",
    "    \n",
    "    candidates = df_data[df_data['cluster'].isin(closest_clusters)].copy()\n",
    "    if candidates.empty: \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    candidate_vectors = X_combined_data[candidates.index]\n",
    "    \n",
    "    user_vec_masked = full_vector[:, valid_idx]  # Slice user vector to only relevant features\n",
    "    cand_vecs_masked = candidate_vectors[:, valid_idx]  # Slice candidate vectors accordingly\n",
    "    \n",
    "    if np.all(user_vec_masked == 0):\n",
    "        scores = np.zeros(len(candidates))\n",
    "    else:\n",
    "        scores = cosine_similarity(user_vec_masked, cand_vecs_masked)[0]  # Masked similarity calculation\n",
    "    \n",
    "    candidates['match_score'] = scores\n",
    "    \n",
    "    # Return: sorted by match_score descending, take top 10, keep only match_score (index included as row identifier)\n",
    "    return candidates.sort_values('match_score', ascending=False).head(10)[['match_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f17b84",
   "metadata": {},
   "source": [
    "# Testing\n",
    "Input options for recommendation engine test cases.\n",
    "\n",
    "Allows generation of random user preference combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb81e3",
   "metadata": {},
   "source": [
    "## Define options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "c9071f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_options = {\n",
    "    'terrain': ['Light', 'Mixed', 'Rocky', 'Muddy'],\n",
    "    'rock_sensitive': ['Yes', 'No'],\n",
    "    'pace': ['Easy', 'Steady', 'Fast'],\n",
    "    'orthotic_usage': ['Yes', 'No'],\n",
    "    'arch_type': ['Low', 'Neutral', 'High'],\n",
    "    'strike_pattern': ['Heel', 'Mid', 'Forefoot'],\n",
    "    'foot_width': ['Narrow', 'Medium', 'Wide'],\n",
    "    'season': ['Summer', 'Spring, Fall', 'Winter'],\n",
    "    'water_resistance': ['Waterproof', 'Water Repellent'],\n",
    "}\n",
    "\n",
    "def generate_random_user_input(num_features):\n",
    "    \"\"\"\n",
    "    Generate randomized user preference input for testing and validation.\n",
    "    \n",
    "    Purpose: Creates realistic test cases with variable input completeness.\n",
    "    \n",
    "    Args:\n",
    "        num_features (int): Number of random features to include\n",
    "    \n",
    "    Returns:\n",
    "        dict: User preferences with num_features random keys/values\n",
    "              e.g., {'pace': 'Fast', 'arch_type': 'Neutral', 'season': 'Summer'}\n",
    "    \"\"\"\n",
    "    all_keys = list(input_options.keys())\n",
    "    selected_keys = random.sample(all_keys, k=min(num_features, len(all_keys)))\n",
    "    \n",
    "    user_input = {}\n",
    "    for key in selected_keys:\n",
    "        user_input[key] = random.choice(input_options[key])\n",
    "        \n",
    "    return user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a36ee",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Test Suite Execution\n",
    "Runs recommendation engine on multiple test cases with varying input completeness.\n",
    "\n",
    "Tests: 3 features (partial), 6 features (moderate), 9 features (complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "116ec942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECOMMENDATION ENGINE TEST SUITE ===\n",
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #1: User providing 3 preferences\n",
      "User Input:\n",
      "{'orthotic_usage': 'Yes', 'arch_type': 'Neutral', 'rock_sensitive': 'Yes'}\n",
      "User mapped to Clusters: [1 4]\n",
      "\n",
      "Top 10 Recommendations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new balance</td>\n",
       "      <td>fresh foam x more trail v3</td>\n",
       "      <td>0.989024</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nike</td>\n",
       "      <td>pegasus trail 5</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new balance</td>\n",
       "      <td>fresh foam x hierro v9</td>\n",
       "      <td>0.966362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoka</td>\n",
       "      <td>mafate 5</td>\n",
       "      <td>0.966362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topo</td>\n",
       "      <td>ultraventure 3</td>\n",
       "      <td>0.966362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keen</td>\n",
       "      <td>seek</td>\n",
       "      <td>0.962761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>asics</td>\n",
       "      <td>trabuco max 3</td>\n",
       "      <td>0.961572</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brooks</td>\n",
       "      <td>caldera 7</td>\n",
       "      <td>0.961572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>asics</td>\n",
       "      <td>gel trabuco 12</td>\n",
       "      <td>0.961276</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saucony</td>\n",
       "      <td>peregrine 14</td>\n",
       "      <td>0.961276</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand                        name  match_score  cluster\n",
       "0  new balance  fresh foam x more trail v3     0.989024        4\n",
       "1         nike             pegasus trail 5     0.976923        1\n",
       "2  new balance      fresh foam x hierro v9     0.966362        1\n",
       "3         hoka                    mafate 5     0.966362        1\n",
       "4         topo              ultraventure 3     0.966362        1\n",
       "5         keen                        seek     0.962761        1\n",
       "6        asics               trabuco max 3     0.961572        4\n",
       "7       brooks                   caldera 7     0.961572        1\n",
       "8        asics              gel trabuco 12     0.961276        4\n",
       "9      saucony                peregrine 14     0.961276        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #2: User providing 6 preferences\n",
      "User Input:\n",
      "{'rock_sensitive': 'Yes', 'season': 'Spring, Fall', 'water_resistance': 'Waterproof', 'strike_pattern': 'Mid', 'pace': 'Steady', 'terrain': 'Rocky'}\n",
      "User mapped to Clusters: [1 4]\n",
      "\n",
      "Top 10 Recommendations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salomon</td>\n",
       "      <td>genesis</td>\n",
       "      <td>0.791216</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asics</td>\n",
       "      <td>trabuco max 3</td>\n",
       "      <td>0.745863</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new balance</td>\n",
       "      <td>fresh foam x more trail v3</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la sportiva</td>\n",
       "      <td>prodigio max</td>\n",
       "      <td>0.726430</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icebug</td>\n",
       "      <td>järv rb9x</td>\n",
       "      <td>0.724886</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asics</td>\n",
       "      <td>gel trabuco 12</td>\n",
       "      <td>0.724610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hoka</td>\n",
       "      <td>tecton x 3</td>\n",
       "      <td>0.714255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>saucony</td>\n",
       "      <td>peregrine 14</td>\n",
       "      <td>0.711835</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brooks</td>\n",
       "      <td>cascadia 17</td>\n",
       "      <td>0.710165</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hoka</td>\n",
       "      <td>mafate speed 4</td>\n",
       "      <td>0.709893</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand                        name  match_score  cluster\n",
       "0      salomon                     genesis     0.791216        4\n",
       "1        asics               trabuco max 3     0.745863        4\n",
       "2  new balance  fresh foam x more trail v3     0.726748        4\n",
       "3  la sportiva                prodigio max     0.726430        4\n",
       "4       icebug                   järv rb9x     0.724886        4\n",
       "5        asics              gel trabuco 12     0.724610        4\n",
       "6         hoka                  tecton x 3     0.714255        1\n",
       "7      saucony                peregrine 14     0.711835        4\n",
       "8       brooks                 cascadia 17     0.710165        4\n",
       "9         hoka              mafate speed 4     0.709893        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "TEST CASE #3: User providing 9 preferences\n",
      "User Input:\n",
      "{'foot_width': 'Wide', 'pace': 'Steady', 'rock_sensitive': 'Yes', 'arch_type': 'Neutral', 'orthotic_usage': 'Yes', 'water_resistance': 'Waterproof', 'terrain': 'Muddy', 'season': 'Winter', 'strike_pattern': 'Mid'}\n",
      "User mapped to Clusters: [3 4]\n",
      "\n",
      "Top 10 Recommendations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>match_score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoka</td>\n",
       "      <td>challenger 7 gtx</td>\n",
       "      <td>0.781385</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salomon</td>\n",
       "      <td>speedcross 6 gtx</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salomon</td>\n",
       "      <td>genesis</td>\n",
       "      <td>0.736631</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merrell</td>\n",
       "      <td>agility peak 5 gtx</td>\n",
       "      <td>0.736309</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icebug</td>\n",
       "      <td>järv rb9x</td>\n",
       "      <td>0.723792</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hoka</td>\n",
       "      <td>speedgoat 5 gtx</td>\n",
       "      <td>0.718814</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>salomon</td>\n",
       "      <td>thundercross</td>\n",
       "      <td>0.718021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>salomon</td>\n",
       "      <td>speedcross 6</td>\n",
       "      <td>0.710240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>asics</td>\n",
       "      <td>trabuco max 3</td>\n",
       "      <td>0.703050</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asics</td>\n",
       "      <td>gel trabuco 12</td>\n",
       "      <td>0.701825</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                name  match_score  cluster\n",
       "0     hoka    challenger 7 gtx     0.781385        3\n",
       "1  salomon    speedcross 6 gtx     0.743422        3\n",
       "2  salomon             genesis     0.736631        4\n",
       "3  merrell  agility peak 5 gtx     0.736309        3\n",
       "4   icebug           järv rb9x     0.723792        4\n",
       "5     hoka     speedgoat 5 gtx     0.718814        3\n",
       "6  salomon        thundercross     0.718021        4\n",
       "7  salomon        speedcross 6     0.710240        3\n",
       "8    asics       trabuco max 3     0.703050        4\n",
       "9    asics      gel trabuco 12     0.701825        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_counts = [3, 6, 9]\n",
    "\n",
    "print(\"=== RECOMMENDATION ENGINE TEST SUITE ===\")\n",
    "\n",
    "for i, count in enumerate(target_counts):\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"TEST CASE #{i+1}: User providing {count} preferences\")\n",
    "    \n",
    "    random_input = generate_random_user_input(count)\n",
    "    print(f\"User Input:\\n{random_input}\")\n",
    "    \n",
    "    try:\n",
    "        recommendations = recommend_shoes_deep_masked(\n",
    "            random_input, \n",
    "            df, \n",
    "            encoder, \n",
    "            best_model, \n",
    "            binary_cols, \n",
    "            continuous_cols, \n",
    "            X_combined\n",
    "        )\n",
    "        \n",
    "        if not recommendations.empty:\n",
    "            print(\"\\nTop 10 Recommendations:\")\n",
    "            # Get brand, name, cluster from original df using index, add match_score from recommendations\n",
    "            result_df = pd.DataFrame({\n",
    "                'brand': df.loc[recommendations.index, 'brand'].values,\n",
    "                'name': df.loc[recommendations.index, 'name'].values,\n",
    "                'match_score': recommendations['match_score'].values,\n",
    "                'cluster': df.loc[recommendations.index, 'cluster'].values\n",
    "            })\n",
    "            display(result_df)\n",
    "        else:\n",
    "            print(\"\\nNo recommendations found (cluster empty).\")\n",
    "            \n",
    "    except NameError:\n",
    "        print(\"\\nERROR: Ensure model and preprocessing functions are loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07ca18",
   "metadata": {},
   "source": [
    "# Save Artifacts\n",
    "Saves 4 artifacts for complete model reconstruction:\n",
    "1. shoe_encoder.keras: Trained autoencoder (feature encoding)\n",
    "2. kmeans_model.pkl: Trained K-means clusters\n",
    "3. shoe_metadata.pkl: Complete shoe dataset with cluster assignments\n",
    "4. shoe_features.pkl: Preprocessed feature matrix (X_combined)\n",
    "\n",
    "Artifacts stored in timestamped versioned directories for traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "02e2f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models to: ../../model_artifacts/trail/v_20260211_110206\n",
      "✓ Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"../../model_artifacts/trail/v_{timestamp}\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"Saving models to: {save_dir}\")\n",
    "\n",
    "encoder.save(f'{save_dir}/shoe_encoder.keras')\n",
    "\n",
    "with open(f'{save_dir}/kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "df.to_pickle(f'{save_dir}/shoe_metadata.pkl')\n",
    "\n",
    "with open(f'{save_dir}/shoe_features.pkl', 'wb') as f:\n",
    "    pickle.dump(X_combined, f)\n",
    "\n",
    "print(\"✓ Models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
